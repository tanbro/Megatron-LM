{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 心理咨询论坛问答语料(无标签平面文本) - 制作迁徙学习数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为 NVIDIA/Megatron-LM 准备该领域的 finetune 数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 用问题与其多个答案中的一个反复组合，形成多个问题-答案对\n",
    "- 使用 tag 或者问题中的关键字，选取一个类型的问答数据作为语料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "来源语料格式举例：\n",
    "\n",
    "```json\n",
    "{'topics': ['婚姻'],\n",
    " 'title': [],\n",
    " 'text': ['其实无论我们遇见谁和谁相恋，无论成功与否都是过程和经历，即便是失败也不要沮丧，我们要回头在那失败的地方我们学到了什么，并且有什么美好的回忆留在心里，在人生道路上，只要我们认真对待感情，正正经经的恋爱，就算被辜负或者遇见错的人而失望，但我相信认真对待生活的人一定会有收获的，再困难再痛苦事情都会过去的，你依然是你，天也不会塌，经历会让我们成长，更懂得生活的意义，才会有精彩的人生。',\n",
    "  '会有那么一个人会看见你的内在，拥抱你真挚的心。',\n",
    "  '我说的对么?'],\n",
    " 'answers': [['是的，', '做好自己，', '勇敢面对一切快乐和痛苦，', '一切源于我们的内心，', '修炼自己']]}\n",
    "```\n",
    "\n",
    "形成的平面带有分隔符的QA语料是：\n",
    "\n",
    "```js\n",
    "    plain_text(title) + \"<sep>\"\n",
    "  + plain_text(text) + plain_text(slave_text) + \"<sep>\"\n",
    "  + \"<sep>\"\n",
    "  + \"<|endoftext|>\" + plain_text(answer)\n",
    "```\n",
    "\n",
    "将输出的语料存放在 JSON Lines 文件中，文本内容放在 `text` 属性中\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CD\n",
    "\n",
    "切换到工作目录(**按实际情况，勿照搬下面的 Cell**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/Public/Megatron-LM\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from copy import copy\n",
    "from contextlib import closing, ExitStack\n",
    "import fileinput\n",
    "from functools import partial\n",
    "from glob import glob, iglob\n",
    "from itertools import chain, repeat\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "from tqdm.auto import tqdm, trange\n",
    "from slugify import slugify\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用与 Pretrained-Model 同样的 tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentencePiece 内置的特殊标记:\n",
      "0 <pad> True\n",
      "1 <unk> False\n",
      "2 <bos> True\n",
      "3 <eos> True\n",
      "4 <sep> False\n",
      "5 <cls> False\n",
      "6 <|endoftext|> False\n",
      "7 一个 False\n",
      "\n",
      "Wrapped tokenizer ...\n",
      "0: <pad>\n",
      "1: <eos>\n",
      "2: <bos>\n",
      "3: <unk>\n",
      "4: <sep>\n",
      "5: <L2R>\n",
      "6: <ENC>\n",
      "7: <MASK>\n",
      "CPU times: user 733 ms, sys: 139 ms, total: 872 ms\n",
      "Wall time: 891 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from data_utils.tokenization import SentencePieceTokenizer, make_tokenizer\n",
    "\n",
    "\n",
    "TOKENIZER_MODEL_PATH='./data/spm/gpt2_huamei_corpus_bpe_32k_v2.model'\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(TOKENIZER_MODEL_PATH)\n",
    "\n",
    "print('SentencePiece 内置的特殊标记:')\n",
    "for i in range(8):\n",
    "  print(i, sp.id_to_piece(i), sp.is_control(i))\n",
    "del sp\n",
    "print()\n",
    "\n",
    "print('Wrapped tokenizer ...')\n",
    "tokenizer = make_tokenizer(\n",
    "    SentencePieceTokenizer,\n",
    "    None,\n",
    "    model_path=TOKENIZER_MODEL_PATH\n",
    ")\n",
    "\n",
    "# tokenizer.command_tokens\n",
    "for tok in tokenizer.command_name_map.values():\n",
    "    print(f'{tok.Id}: {tok.token}')\n",
    "\n",
    "# 需要的特殊标记：\n",
    "SEP = '<sep>'\n",
    "START_OF_ANSWER = '<|endoftext|>'\n",
    "\n",
    "for piece in (SEP, START_OF_ANSWER):\n",
    "    assert piece == tokenizer.IdToToken(tokenizer.TokenToId(piece))\n",
    "    assert piece == tokenizer.IdToToken(tokenizer.EncodeAsIds(piece).tokenization[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_files = glob('/home/Public/data/transfer-learning/output/output-qa/xinli001_jiandanxinli-qa.topics/*.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "语料文件:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/Public/data/transfer-learning/output/output-qa/xinli001_jiandanxinli-qa.topics/valid_xinli_qax.json',\n",
       " '/home/Public/data/transfer-learning/output/output-qa/xinli001_jiandanxinli-qa.topics/train_xinli_qax.json',\n",
       " '/home/Public/data/transfer-learning/output/output-qa/xinli001_jiandanxinli-qa.topics/test_xinli_qax.json']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14731919cfac4ac48233619b36124c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "总行数: 187,156\n"
     ]
    }
   ],
   "source": [
    "print('语料文件:')\n",
    "display(corpus_files)\n",
    "print()\n",
    "\n",
    "with fileinput.input(corpus_files) as reader:\n",
    "    total = sum(1 for _ in tqdm(reader, unit='line'))\n",
    "\n",
    "print(f'总行数: {total:,d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在预览语料数据格式，随机选择一个："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c88f37a2114c489ae15fd01dfb538a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20804), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20803"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'topics': ['性心理', '性心理'],\n",
       " 'title': ['哇啊啊啊啊啊，我是不是变态啊！'],\n",
       " 'text': ['咳咳咳，今天我朋友给我看A片我看了一点就觉得无趣，还有点恶心。',\n",
       "  '但是我看耽美的时候我特别感觉兴奋，还有点小激动。',\n",
       "  '我是女的哦！',\n",
       "  '（当然我讨厌百合，也觉得恶心），我前世是不是一个男的，而且还是骨灰级断袖啊。',\n",
       "  '求卍解'],\n",
       " 'answers': [['你好，',\n",
       "   '我是小媒。',\n",
       "   '腐女，',\n",
       "   '指支持BL，',\n",
       "   '赞美男男爱情的女性。',\n",
       "   '这种心理可能产生于这几个方面。',\n",
       "   '1防御心理。',\n",
       "   '因为家庭教育中对于性的教育比较缺乏，',\n",
       "   '并且存在一种“性是禁区”的思想。',\n",
       "   '当我们为了避免男女之间的性，',\n",
       "   '渐渐将目光转向男性之间。',\n",
       "   '2嫉妒心理。',\n",
       "   '既然得不到男神，',\n",
       "   '那就让男神和男神在一起吧！',\n",
       "   '用叔本华来解释腐女们的世界：基情虽是她们看到的表象，',\n",
       "   '背后恐怕是难以填埋的欲望。',\n",
       "   '她们的原则就是，',\n",
       "   '宁可美男出双入对，',\n",
       "   '不可让其落入敌手。',\n",
       "   '既然男人有后宫情结，',\n",
       "   '常幻想坐拥佳丽三千，',\n",
       "   '女人自然也有幻想左拥右抱帅哥的邪念。',\n",
       "   '3观察者心理。',\n",
       "   '由于成长经历或是文化熏陶，',\n",
       "   '男女之间的性被看为是肮脏的。',\n",
       "   '而在欣赏耽美作品时，',\n",
       "   '可以以一种更加纯粹的观察者角度来看爱情、性。',\n",
       "   '我身边也有一些腐女，',\n",
       "   '大多都是从青春期开始，',\n",
       "   '到大学还腐的已经是少数。',\n",
       "   '即使是，',\n",
       "   '也能清楚地分清想象和现实，',\n",
       "   '只将耽美放在想象里，',\n",
       "   '不会影响现实生活。',\n",
       "   '所以楼主不用太担心~过了这个时期就会好起来。',\n",
       "   '如果的确很担心的话，',\n",
       "   '也可以咨询专业咨询师哦~（以上部分内容来自百度）']]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n = random.randint(0, total)\n",
    "\n",
    "with fileinput.input(corpus_files) as reader:\n",
    "    for i, line in tqdm(zip(range(n), reader), total=n):\n",
    "        if i+1 < n:\n",
    "            continue\n",
    "        data = json.loads(line)\n",
    "        display(i)\n",
    "        display(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### 采样条件\n",
    "\n",
    "我们应：\n",
    "\n",
    "- 选取问题+回答构成输入样本\n",
    "- 一个问题可以对应多个回答\n",
    "- 不要太短的\n",
    "- 不要太长的\n",
    "- 指定的主题\n",
    "\n",
    "在此基础上，随机乱序选用若干样本用于今次的开发"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 主题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC = '婚姻'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 长度限制定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_QUESTION_LENGTH = 16\n",
    "MAX_QUESTION_LENGTH = 1024\n",
    "MIN_ANSWER_LENGTH = 32\n",
    "MAX_LENGTH = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 样本过滤函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_samples(line):\n",
    "    line = line.strip()\n",
    "    if not line:\n",
    "        return []\n",
    "    data = json.loads(line)\n",
    "    result = []\n",
    "#     # 主题不对的不要！\n",
    "    topics = data.get('topics', []) \n",
    "    if TOPIC not in topics:\n",
    "        return []\n",
    "    # 没有回答的不要\n",
    "    if not data.get('answers'):\n",
    "        return []\n",
    "    # 问题:\n",
    "    title = ''.join(data['title']).strip()\n",
    "    text = ''.join(data['text']).strip()\n",
    "    # 既没有问题标题又没有问题内容的不要\n",
    "    if not title and not text:\n",
    "        return []\n",
    "    n_title = len(tokenizer.EncodeAsIds(title))\n",
    "    n_text = len(tokenizer.EncodeAsIds(text))\n",
    "    # 太短不要\n",
    "    if n_title + n_text < MIN_QUESTION_LENGTH:\n",
    "        return []\n",
    "    # 太长不要\n",
    "    if n_title + n_text > MAX_QUESTION_LENGTH:\n",
    "        return []\n",
    "    # 回答：\n",
    "    question_string = title + SEP + text + SEP\n",
    "    # 答案\n",
    "    for answer in data.get('answers', []):\n",
    "        text = ''.join(answer).strip()\n",
    "        length = len(tokenizer.EncodeAsIds(text))\n",
    "        # 太短不要\n",
    "        if length < MIN_ANSWER_LENGTH:\n",
    "            continue\n",
    "        # 太长不要\n",
    "        if n_title + n_text + length > MAX_LENGTH:\n",
    "            continue\n",
    "        result.append(question_string + SEP + START_OF_ANSWER + text)\n",
    "    #\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 进行采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "657f936636d4474baf7bd60cd1a46f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=187156), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb4e8f9284d44d59919cd15952d1643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=187156), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "样本数量: 49,810\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "\n",
    "with Pool() as pool, fileinput.input(corpus_files) as reader:\n",
    "    mapper = pool.imap_unordered(\n",
    "        extract_samples,\n",
    "        tqdm(reader, total=total),\n",
    "        chunksize=min(1024, total//os.cpu_count()+1)\n",
    "    )\n",
    "    for data_list in tqdm(mapper, total=total):\n",
    "        samples.extend(data_list)\n",
    "\n",
    "print(f'样本数量: {len(samples):,d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预览一条采样结果数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "老婆出轨了，我该怎么办?<sep>我很想和她分手，可是我们有两个孩子，分手了孩子怎么办？不分手又难受，恨这对狗男女的冲动，我该怎么办？很难受<sep><sep><|endoftext|>这真是一个糟糕的经历，哥们儿，先等等自己，允许自己痛苦一阵子，再说怎么办。内心受伤了，先疗愈自己的伤口，如果带着伤，还去奋战，那受伤的伤口，流血更多，内心更痛。\n"
     ]
    }
   ],
   "source": [
    "s = random.choice(samples)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 保存结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出目录: /home/Public/Megatron-LM/data/xinliqa-hun_yin\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = os.path.abspath(\n",
    "    os.path.join(\n",
    "        'data',\n",
    "        'xinliqa-{0}'.format(slugify(TOPIC, separator='_')),\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f'输出目录: {OUTPUT_DIR}')\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 不划分数据集保存\n",
    "\n",
    "乱序后直接保存所有输出样本到文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存所有符合条件的样本到文件: /home/Public/Megatron-LM/data/xinliqa-hun_yin/qa.all.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "067104bb0c284698840fc57ceb3c2acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=49810), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dst_file = os.path.join(\n",
    "    OUTPUT_DIR,\n",
    "    'qa.all.json'\n",
    ")\n",
    "\n",
    "print(f'保存所有符合条件的样本到文件: {dst_file}')\n",
    "\n",
    "with open(dst_file, 'w') as fp:\n",
    "    random.shuffle(samples)\n",
    "    for txt in tqdm(samples):\n",
    "        print(json.dumps({'text': txt}, ensure_ascii=False), file=fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查文件:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56M\t/home/Public/Megatron-LM/data/xinliqa-hun_yin/qa.all.json\n",
      "49810 /home/Public/Megatron-LM/data/xinliqa-hun_yin/qa.all.json\n"
     ]
    }
   ],
   "source": [
    "!du -lh {dst_file}\n",
    "!wc -l {dst_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### 划分数据集保存\n",
    "\n",
    "更复杂的情况，划分数据集再保存\n",
    "\n",
    "根据实际的样本数量，划分为 train/val/test，其样本数量应根据采样情况进行规定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集划分：\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 45000, 'val': 2000, 'test': 2000}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parts = {\n",
    "    'train': 45_000,\n",
    "    'val': 2_000,\n",
    "    'test': 2_000,\n",
    "}\n",
    "\n",
    "print('数据集划分：')\n",
    "display(parts)\n",
    "\n",
    "assert sum(parts.values()) <= len(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 随机选择+洗牌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机种子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.5 ms, sys: 81 µs, total: 51.6 ms\n",
      "Wall time: 50.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "seeds = []\n",
    "seeds.extend(chain.from_iterable(\n",
    "    repeat(k, v) for k, v in parts.items()\n",
    "))\n",
    "seeds.extend(repeat(None, len(samples)-sum(parts.values())))\n",
    "random.shuffle(seeds)\n",
    "\n",
    "assert len(seeds) == len(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 写目标文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出文件:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': '/home/Public/Megatron-LM/data/xinliqa-hun_yin/qa.train.json',\n",
       " 'val': '/home/Public/Megatron-LM/data/xinliqa-hun_yin/qa.val.json',\n",
       " 'test': '/home/Public/Megatron-LM/data/xinliqa-hun_yin/qa.test.json'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80cc3236ced84bdcb9c1c9f7c4d2bc60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=49810), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dst_files_dict = {\n",
    "    k: os.path.join(OUTPUT_DIR, f'qa.{k}.json')\n",
    "    for k in parts.keys()\n",
    "}\n",
    "\n",
    "print('输出文件:')\n",
    "display(dst_files_dict)\n",
    "\n",
    "with ExitStack() as stack, fileinput.input(corpus_files) as reader:\n",
    "    files = {\n",
    "        k: stack.enter_context(open(v, 'w'))\n",
    "        for k, v in dst_files_dict.items()\n",
    "    }\n",
    "    for seed, string in tqdm(zip(seeds, samples), total=len(samples)):\n",
    "        fp = files.get(seed)\n",
    "        if not fp:\n",
    "            continue\n",
    "        print(\n",
    "            json.dumps({'text': string}, ensure_ascii=False),\n",
    "            file=fp\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查输出文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   45000 /home/Public/Megatron-LM/data/xinliqa-hun_yin/qa.train.json\n",
      "    2000 /home/Public/Megatron-LM/data/xinliqa-hun_yin/qa.val.json\n",
      "    2000 /home/Public/Megatron-LM/data/xinliqa-hun_yin/qa.test.json\n",
      "   49000 总用量\n",
      "\n",
      "51M\t/home/Public/Megatron-LM/data/xinliqa-hun_yin/qa.train.json\n",
      "2.2M\t/home/Public/Megatron-LM/data/xinliqa-hun_yin/qa.val.json\n",
      "2.3M\t/home/Public/Megatron-LM/data/xinliqa-hun_yin/qa.test.json\n",
      "55M\t总用量\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = ' '.join(dst_files_dict.values())\n",
    "\n",
    "!wc -l {s}\n",
    "print()\n",
    "\n",
    "!du -hc {s}\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'准备要结婚了，可是发现自己原来很恐婚，没有安全感<sep>今年28，和男友相恋一年，打算明年结婚，可是随着婚期临近遇到很多事情，所以对于婚姻越来越恐惧。其实在很早单身的时候就对婚姻有一种模糊的恐惧感，但是也没有太在意，就是怕结婚之后对方会突然死掉，和好朋友说了之后她们觉得我想太多了，我自己也觉得这个想法不切实际。后来有了男友，父母并不满意，但是也没有要求必须分开，她们保留意见。现在打算要结婚，涉及到一些金钱方面的问题，具体就是男友不出彩礼不买钻戒，单独给我和我家的东西他都很排斥，他说因为没钱，但是买了房付了首付，装修好了，以后贷款他还，父母对此很不满并且预言了我以后生活的种种不幸福，我尝试和男友还有父母沟通过，但是失败了。现在父母的不满意和预言的不幸福，男友的坚硬态度，我父母对男友的不满，种种压力让我的恐惧感又出现了，我该怎么办<sep><sep><|endoftext|>你在恐惧什么，你没说清楚。是对未来生活的未知恐惧还是对男友的认知和行为不匹配时的恐惧还是对家人和对方家人矛盾的恐惧还是对自己能否幸福怀疑的恐惧具体点 铁汁'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/home/Public/Megatron-LM/data/xinli_qa_artical-hunyin/qa.test.json') as fp:\n",
    "    for line in fp:\n",
    "        data = json.loads(line)\n",
    "        text = data['text']\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8787 \n",
      "363 准备\n",
      "8826 要\n",
      "725 结婚\n",
      "8792 了\n",
      "8785 ,\n",
      "194 可是\n",
      "6662 发现自己\n",
      "638 原来\n",
      "8879 很\n",
      "9790 恐\n",
      "9461 婚\n",
      "8785 ,\n",
      "20 没有\n",
      "4743 安全感\n",
      "12 <sep>\n",
      "680 今年\n",
      "1244 28\n",
      "8785 ,\n",
      "8828 和\n",
      "2550 男友\n",
      "8966 相\n",
      "9801 恋\n",
      "646 一年\n",
      "8785 ,\n",
      "1479 打算\n",
      "4279 明年\n",
      "725 结婚\n",
      "8785 ,\n",
      "194 可是\n",
      "811 随着\n",
      "9461 婚\n",
      "9064 期\n",
      "9731 临\n",
      "9195 近\n",
      "887 遇到\n",
      "107 很多\n",
      "356 事情\n",
      "8785 ,\n",
      "64 所以\n",
      "204 对于\n",
      "1255 婚姻\n",
      "643 越来越\n",
      "1884 恐惧\n",
      "8788 。\n",
      "156 其实\n",
      "8796 在\n",
      "8879 很\n",
      "9253 早\n",
      "4627 单身\n",
      "76 的时候\n",
      "8814 就\n",
      "8847 对\n",
      "1255 婚姻\n",
      "1737 有一种\n",
      "3820 模糊\n",
      "8786 的\n",
      "1884 恐惧\n",
      "8959 感\n",
      "8785 ,\n",
      "61 但是\n",
      "590 也没有\n",
      "8998 太\n",
      "3850 在意\n",
      "8785 ,\n",
      "29 就是\n",
      "9391 怕\n",
      "725 结婚\n",
      "146 之后\n",
      "462 对方\n",
      "8830 会\n",
      "327 突然\n",
      "9115 死\n",
      "9622 掉\n",
      "8785 ,\n",
      "8828 和\n",
      "6903 好朋友\n",
      "783 说了\n",
      "146 之后\n",
      "636 她们\n",
      "75 觉得\n",
      "364 我想\n",
      "4720 太多了\n",
      "8785 ,\n",
      "2224 我自己\n",
      "8824 也\n",
      "75 觉得\n",
      "31 这个\n",
      "899 想法\n",
      "8791 不\n",
      "9318 切\n",
      "472 实际\n",
      "8788 。\n",
      "246 后来\n",
      "611 有了\n",
      "2550 男友\n",
      "8785 ,\n",
      "365 父母\n",
      "361 并不\n",
      "2208 满意\n",
      "8785 ,\n",
      "61 但是\n",
      "590 也没有\n",
      "291 要求\n",
      "286 必须\n",
      "4331 分开\n",
      "8785 ,\n",
      "636 她们\n",
      "3191 保留\n",
      "1087 意见\n",
      "8788 。\n",
      "42 现在\n",
      "1479 打算\n",
      "8826 要\n",
      "725 结婚\n",
      "8785 ,\n",
      "2411 涉及\n",
      "8818 到\n",
      "166 一些\n",
      "4154 金钱\n",
      "190 方面\n",
      "467 的问题\n",
      "8785 ,\n",
      "856 具体\n",
      "29 就是\n",
      "2550 男友\n",
      "1096 不出\n",
      "9903 彩\n",
      "9627 礼\n",
      "8791 不\n",
      "9277 买\n",
      "10681 钻\n",
      "10496 戒\n",
      "8785 ,\n",
      "3804 单独\n",
      "474 给我\n",
      "1314 和我\n",
      "8861 家\n",
      "584 的东西\n",
      "8800 他\n",
      "1892 都很\n",
      "8449 排斥\n",
      "8785 ,\n",
      "490 他说\n",
      "40 因为\n",
      "7688 没钱\n",
      "8785 ,\n",
      "61 但是\n",
      "2370 买了\n",
      "9169 房\n",
      "9752 付\n",
      "8792 了\n",
      "9235 首\n",
      "9752 付\n",
      "8785 ,\n",
      "4405 装修\n",
      "525 好了\n",
      "8785 ,\n",
      "226 以后\n",
      "2353 贷款\n",
      "2761 他还\n",
      "8785 ,\n",
      "365 父母\n",
      "2377 对此\n",
      "2735 很不\n",
      "9246 满\n",
      "485 并且\n",
      "9607 预\n",
      "9177 言\n",
      "1236 了我\n",
      "226 以后\n",
      "2189 生活的\n",
      "2893 种种\n",
      "8791 不\n",
      "732 幸福\n",
      "8785 ,\n",
      "8793 我\n",
      "1985 尝试\n",
      "8828 和\n",
      "2550 男友\n",
      "123 还有\n",
      "365 父母\n",
      "10295 沟\n",
      "228 通过\n",
      "8785 ,\n",
      "61 但是\n",
      "1211 失败\n",
      "8792 了\n",
      "8788 。\n",
      "42 现在\n",
      "365 父母\n",
      "1079 的不\n",
      "2208 满意\n",
      "8828 和\n",
      "9607 预\n",
      "9177 言\n",
      "1079 的不\n",
      "732 幸福\n",
      "8785 ,\n",
      "2550 男友\n",
      "8786 的\n",
      "9682 坚\n",
      "9972 硬\n",
      "938 态度\n",
      "8785 ,\n",
      "8793 我\n",
      "365 父母\n",
      "8847 对\n",
      "2550 男友\n",
      "1079 的不\n",
      "9246 满\n",
      "8785 ,\n",
      "2893 种种\n",
      "833 压力\n",
      "8996 让\n",
      "57 我的\n",
      "1884 恐惧\n",
      "8959 感\n",
      "8950 又\n",
      "2204 出现了\n",
      "8785 ,\n",
      "8746 我该怎么办\n",
      "12 <sep>\n",
      "12 <sep>\n",
      "14 <|endoftext|>\n",
      "1624 你在\n",
      "1884 恐惧\n",
      "19 什么\n",
      "8785 ,\n",
      "6855 你没\n",
      "8820 说\n",
      "495 清楚\n",
      "8788 。\n",
      "2276 是对\n",
      "839 未来\n",
      "2189 生活的\n",
      "7851 未知\n",
      "1884 恐惧\n",
      "51 还是\n",
      "8847 对\n",
      "2550 男友\n",
      "8786 的\n",
      "4109 认知\n",
      "8828 和\n",
      "458 行为\n",
      "8791 不\n",
      "10678 匹\n",
      "9574 配\n",
      "939 时的\n",
      "1884 恐惧\n",
      "51 还是\n",
      "8847 对\n",
      "1380 家人\n",
      "8828 和\n",
      "462 对方\n",
      "1380 家人\n",
      "1509 矛盾\n",
      "8786 的\n",
      "1884 恐惧\n",
      "51 还是\n",
      "2562 对自己\n",
      "3702 能否\n",
      "732 幸福\n",
      "1410 怀疑\n",
      "8786 的\n",
      "1884 恐惧\n",
      "856 具体\n",
      "8906 点\n",
      "8787 \n",
      "9548 铁\n",
      "10944 汁\n"
     ]
    }
   ],
   "source": [
    "for id_ in tokenizer.EncodeAsIds(text):\n",
    "    print(id_, tokenizer.DecodeIds([id_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Megatron_LM-ipy]",
   "language": "python",
   "name": "conda-env-Megatron_LM-ipy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
