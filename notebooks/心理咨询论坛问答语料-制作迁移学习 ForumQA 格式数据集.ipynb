{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ForumQA 格式的心理咨询论坛问答语料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为 NVIDIA/Megatron-LM 准备该领域的 finetune 数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 要点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用教少量的心理咨询论坛问答数据，在之前的泛情绪类预训练模型基础上进行 finetune\n",
    "- 我们自己规定的 ForumQA 格式和我们按照这个格式修改的训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "论坛 QA 包括：\n",
    "\n",
    "* 问题标题\n",
    "* 问题正文\n",
    "* 问题类型标签列表\n",
    "* 回答列表\n",
    "\n",
    "这个数据集是一个 Infinit(Iterable-style) datasets，他将问题与类型、回答反复组合，循环迭代，返回给 Dataloader\n",
    "\n",
    "数据文件是 JSON lines 格式，每一行都是 JSON Object,其格式形如::\n",
    "\n",
    "    {\n",
    "        title: \"...\",\n",
    "        text: \"...\",\n",
    "        tags: [\"...\", \"...\"],  # Optional\n",
    "        answers: [\n",
    "            {text: \"...\"},\n",
    "            {text: \"...\"},\n",
    "            # ...\n",
    "            {text: \"...\"},\n",
    "        ]\n",
    "    }\n",
    "\n",
    "返回的数据是 token ID 的一维数组，形如::\n",
    "\n",
    "    xxxxx<sep>xxxxxx[<sep>xxxx]<sep><sep>[bos]xxxxxxxxx[eos]\n",
    "    Title      Text      tag                    Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from copy import copy\n",
    "from contextlib import closing, ExitStack\n",
    "from functools import partial\n",
    "from glob import glob, iglob\n",
    "from fileinput import FileInput\n",
    "from itertools import chain, repeat\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用与 Pretrained-Model 同样的 tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spm_model_path = '../data/spm/gpt2_huamei_corpus_bpe_32k_v2.model'\n",
    "\n",
    "tokenizer = spm.SentencePieceProcessor()\n",
    "tokenizer.load(spm_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_files = [\n",
    "    '/home/liuxy/Public/yiren-scrapy-crawlers/data/[xinli001+jiandanxinli]-qa[191010].jsonl',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "语料文件:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/liuxy/Public/yiren-scrapy-crawlers/data/[xinli001+jiandanxinli]-qa[191010].jsonl']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7645be8488e4cd5916bd170ab6e34b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "总行数: 200,526\n"
     ]
    }
   ],
   "source": [
    "print('语料文件:')\n",
    "display(corpus_files)\n",
    "print()\n",
    "\n",
    "it = FileInput(corpus_files)\n",
    "total = sum(1 for _ in tqdm(it, unit='line'))\n",
    "\n",
    "print(f'总行数: {total:,d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在预览语料数据格式，随机选择一个："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a385b800fe24b198b19ae1f4c629945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=87419), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "87418"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': 100037650,\n",
       " 'url': 'https://www.xinli001.com/qa/100037650',\n",
       " 'crawl_time': '2019-09-23 05:04:33',\n",
       " 'user_url': 'https://www.xinli001.com/user/11393641',\n",
       " 'answers': [{'page': 2,\n",
       "   'user_url': 'https://www.xinli001.com/user/1001010141',\n",
       "   'user_name': '王永馥',\n",
       "   'user_title': '',\n",
       "   'reward': None,\n",
       "   'like_num': 1,\n",
       "   'time': '2017-02-16',\n",
       "   'comment_num': 0,\n",
       "   'comments': [],\n",
       "   'text': '说句你不爱听的，这男友也太自私了点，但是女生在被需要时感觉很有价值感，就对上了。'}],\n",
       " 'title': '异地恋男友非要我去找他',\n",
       " 'answer_num': 1,\n",
       " 'time': '2017-02-16',\n",
       " 'read_num': 607,\n",
       " 'text': '他在外地上学 我还在家里。说实话我父母嫌他家里穷不让我和他在一起。可是我真的很喜欢他，我不管他穷不穷只要我们一起努力肯定饿不死。可是他上学去了天天问我怎么不去找他，我是真的不能去找他，我爸妈知道了非被我气死不可。我真的是不知道怎么办。我就想他在学校好好读书好好考研，可他天天就只会说想我让我快点去。哎~~~',\n",
       " 'tags': ['婚姻']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n = random.randint(0, total)\n",
    "\n",
    "it = FileInput(corpus_files)\n",
    "for i, line in tqdm(zip(range(n), it), total=n):\n",
    "    if i+1 < n:\n",
    "        continue\n",
    "    data = json.loads(line)\n",
    "    display(i)\n",
    "    display(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 过滤条件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们应：\n",
    "\n",
    "- 选取问题+回答构成输入样本\n",
    "- 一个问题可以对应多个回答\n",
    "- 不要太短的\n",
    "- 不要太长的\n",
    "- 只返回需要的属性\n",
    "\n",
    "在此基础上，选用 `10,000` 个样本用于今次的开发"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 长短限制定义：\n",
    "\n",
    "MIN_QUESTION_LENGTH = 16\n",
    "MAX_QUESTION_LENGTH = 1024\n",
    "MIN_ANSWER_LENGTH = 32\n",
    "MAX_LENGTH = 2048\n",
    "\n",
    "\n",
    "def filter_sample(line):\n",
    "    line = line.strip()\n",
    "    if not line:\n",
    "        return None\n",
    "    data = json.loads(line)\n",
    "    # 裁减属性\n",
    "    attrs = list(data.keys())\n",
    "    for attr in attrs:\n",
    "        if attr not in ('title', 'text', 'tags', 'answers'):\n",
    "            del data[attr]\n",
    "    #\n",
    "    tags = data.get('tags', []) \n",
    "    # 没有主题的不要\n",
    "#     if not tags:\n",
    "#         return []\n",
    "    # 问题:\n",
    "    title = data['title']\n",
    "    # 没有标题的不要\n",
    "    if not title:\n",
    "        return None\n",
    "    text = data['text']\n",
    "    # 没有问题内容的不要\n",
    "    if not text:\n",
    "        return []\n",
    "    # 没有回答的不要\n",
    "    if not data.get('answers'):\n",
    "        return None\n",
    "    n_title = len(tokenizer.encode_as_ids(title))\n",
    "    n_text = len(tokenizer.encode_as_ids(text))\n",
    "    # 太短不要\n",
    "    if n_title + n_text < MIN_QUESTION_LENGTH:\n",
    "        return None\n",
    "    # 太长不要\n",
    "    if n_title + n_text > MAX_QUESTION_LENGTH:\n",
    "        return None\n",
    "    # 答案长度检查\n",
    "    answers = []\n",
    "    for answer in data['answers']:\n",
    "        text = answer['text']\n",
    "        length = len(tokenizer.encode_as_ids(text))\n",
    "        # 太短不要\n",
    "        if length < MIN_ANSWER_LENGTH:\n",
    "            continue\n",
    "        # 太长不要\n",
    "        if n_title + n_text + length > MAX_LENGTH:\n",
    "            continue\n",
    "        # 裁减属性\n",
    "        attrs = list(answer.keys())\n",
    "        for attr in attrs:\n",
    "            if attr not in ('text',):\n",
    "                del answer[attr]\n",
    "        #\n",
    "        answers.append(answer)\n",
    "    # 答案过滤后没有了的不要\n",
    "    if not answers:\n",
    "        return None\n",
    "    data['answers'] = answers\n",
    "    #\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用上一次随机取得的行试试看："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_sample(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 过滤全部样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0354cd5d564545b8b88b38df32318d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200526), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6105f62a553e45369f2143cfd76f50a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200526), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "满足过滤条件的样本个数: 149,423/200,526 (74.51552417142913%)\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "\n",
    "with FileInput(corpus_files) as fp, Pool() as pool:\n",
    "    mapper = pool.imap_unordered(\n",
    "        filter_sample,\n",
    "        tqdm(fp, total=total),\n",
    "        chunksize=64\n",
    "    )\n",
    "    samples = [\n",
    "        d\n",
    "        for d\n",
    "        in tqdm(mapper, total=total)\n",
    "        if d\n",
    "    ]\n",
    "\n",
    "print(f'满足过滤条件的样本个数: {len(samples):,d}/{total:,d} ({len(samples)/total*100}%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 💡 **Tips**:\n",
    ">\n",
    "> 我们可以反复调整过滤条件，直到满足的样本个数达到要求"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更具过滤后的样本个数划分 train/val/test 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集划分：\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 140000, 'val': 5000, 'test': 4000}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parts = {\n",
    "    'train': 140_000,\n",
    "    'val': 5_000,\n",
    "    'test': 4_000,\n",
    "}\n",
    "\n",
    "print('数据集划分：')\n",
    "display(parts)\n",
    "\n",
    "assert sum(parts.values()) <= len(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机/洗牌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机种子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 314 ms, sys: 0 ns, total: 314 ms\n",
      "Wall time: 312 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "seeds = []\n",
    "seeds.extend(chain.from_iterable(\n",
    "    repeat(k, v) for k, v in parts.items()\n",
    "))\n",
    "seeds.extend(repeat(None, len(samples)-sum(parts.values())))\n",
    "random.shuffle(seeds)\n",
    "random.shuffle(samples)\n",
    "\n",
    "assert len(seeds) == len(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 输出文件路径\n",
    "\n",
    "保存为我们自己规定的 ForumQA Loose Json 格式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出文件:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': '../data/xinliqa/train.json',\n",
       " 'val': '../data/xinliqa/val.json',\n",
       " 'test': '../data/xinliqa/test.json'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.95 ms, sys: 2.52 ms, total: 7.47 ms\n",
      "Wall time: 4.74 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "output_dir = '../data/xinliqa'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "output_files = {\n",
    "    k: os.path.join(output_dir, f'{k}.json')\n",
    "    for k in parts.keys()\n",
    "}\n",
    "\n",
    "print('输出文件:')\n",
    "display(output_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 写目标文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda96b1203624a90969ea220db47ee2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=149423), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lines_iter = FileInput(corpus_files)\n",
    "\n",
    "with ExitStack() as stack:\n",
    "    files = {\n",
    "        k: stack.enter_context(open(v, 'w'))\n",
    "        for k, v in output_files.items()\n",
    "    }\n",
    "    for seed, sample in tqdm(zip(seeds, samples), total=len(samples)):\n",
    "        fp = files.get(seed)\n",
    "        if not fp:\n",
    "            continue\n",
    "        print(\n",
    "            json.dumps(sample, ensure_ascii=False),\n",
    "            file=fp\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查输出文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   140000 ../data/xinliqa/train.json\n",
      "     5000 ../data/xinliqa/val.json\n",
      "     4000 ../data/xinliqa/test.json\n",
      "   149000 总用量\n",
      "\n",
      "248M\t../data/xinliqa/train.json\n",
      "8.7M\t../data/xinliqa/val.json\n",
      "6.9M\t../data/xinliqa/test.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = ' '.join(output_files.values())\n",
    "\n",
    "!wc -l {s}\n",
    "print()\n",
    "\n",
    "!du -h {s}\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Megatron_LM-ipy]",
   "language": "python",
   "name": "conda-env-Megatron_LM-ipy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
