{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 心理咨询论坛问答语料 - 制作迁徙学习数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为 NVIDIA/Megatron-LM 准备该领域的 finetune 数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 要点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用教少量的心理咨询论坛问答数据，在之前的泛情绪类预训练模型基础上进行 finetune\n",
    "- 使用特殊标记(Token) 分隔问题标题、文本、答案文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from copy import copy\n",
    "from contextlib import closing, ExitStack\n",
    "from functools import partial\n",
    "from glob import glob, iglob\n",
    "from fileinput import FileInput\n",
    "from itertools import chain, repeat\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用与 Pretrained-Model 同样的 tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spm_model_path = '../data/spm/gpt2_huamei_corpus_bpe_32k_v2.model'\n",
    "\n",
    "tokenizer = spm.SentencePieceProcessor()\n",
    "tokenizer.load(spm_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特殊标记\n",
    "\n",
    "该 Tokenizer 既有的特殊标记有："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <pad> True\n",
      "1 <unk> False\n",
      "2 <bos> True\n",
      "3 <eos> True\n",
      "4 <sep> False\n",
      "5 <cls> False\n",
      "6 <|endoftext|> False\n",
      "7 一个 False\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "  print(i, tokenizer.id_to_piece(i), tokenizer.is_control(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们选用：\n",
    "\n",
    "- 连续两个`<sep>` 表示问题与回答的间隔\n",
    "- 一个 `<sep>` 表示问题中，标题、正文、类型的分隔\n",
    "- 每个类型标签文本的开头，加上`<cls>`\n",
    "\n",
    "格式是：\n",
    "\n",
    "```\n",
    "<title-of-question><sep><text-of-question><seq>[[<cls>category1,][[<cls>category2,] ... ]<sep><sep><text-of-answer>\n",
    "```\n",
    "\n",
    "例如：\n",
    "\n",
    "```\n",
    "脸上长痘痘怎么办？<sep><cls>健康<cls>面部护理<sep>我18岁，脸上有很多豆豆，流脓，老不好，吃了很多药，怎么办？<sep><sep>看了楼主的问题，我感动深受，建立你来苗医生！\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sep> <cls>\n"
     ]
    }
   ],
   "source": [
    "SEP = tokenizer.id_to_piece(4)\n",
    "CLS = tokenizer.id_to_piece(5)\n",
    "\n",
    "print(\n",
    "    SEP,\n",
    "    CLS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_files = glob('/home/Public/data/transfer-learning/output/output-qa/xinli001_jiandanxinli-qa.topics/*.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "语料文件:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/Public/data/transfer-learning/output/output-qa/xinli001_jiandanxinli-qa.topics/valid_xinli_qax.json',\n",
       " '/home/Public/data/transfer-learning/output/output-qa/xinli001_jiandanxinli-qa.topics/train_xinli_qax.json',\n",
       " '/home/Public/data/transfer-learning/output/output-qa/xinli001_jiandanxinli-qa.topics/test_xinli_qax.json']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a561f0896334fd096cf42210ea08a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "总行数: 187,156\n"
     ]
    }
   ],
   "source": [
    "print('语料文件:')\n",
    "display(corpus_files)\n",
    "print()\n",
    "\n",
    "it = FileInput(corpus_files)\n",
    "total = sum(1 for _ in tqdm(it, unit='line'))\n",
    "\n",
    "print(f'总行数: {total:,d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在预览语料数据格式，随机选择一个："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708a7e3d188842efb49d17c2391345e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=108937), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "108936"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'topics': ['人格特质', '情绪', '情绪调节'],\n",
       " 'title': ['因为减肥而带来心理疾病，该怎么办？'],\n",
       " 'text': ['可能从16岁开始吧，我就对减肥很执着，一直都在努力减肥，现在163/52kg想着继续减肥，继母家里的人从小都说我很胖，我心里很受打击，就一直在减肥，最近一年吧就开始发现自己心理好像越来越不正常了，吃饭的时候不敢吃，吃完了就很难过觉得自己会长胖，然后就进入了节食的状态，节食了两三天后又暴食，吃到胃很撑很难受的那种，然后心情就会很难过，很讨厌自己为什么吃这么多，不吃饭的时候自己也在反思说为什么要这样，为什么要节食，为什么要减肥',\n",
       "  '现在很害怕吃东西，也很害怕看到食物，怕自己忍不住往嘴里塞东西，以前吃东西感觉到开心，现在不知道什么是开心，对什么事情都提不起兴趣，很不喜欢这样的自己，不知道该怎么办'],\n",
       " 'answers': [['您好，',\n",
       "   '看您的描述，',\n",
       "   '已经不单只是减肥的问题了，',\n",
       "   '应该属于临床上比较常见的体象障碍和神经性贪食、厌食症，',\n",
       "   '建议到医院确诊一下，',\n",
       "   '同时配合心理治疗，',\n",
       "   '才有较好的效果。',\n",
       "   '另外，',\n",
       "   '神经症厌食在精神分析的理解框架下，',\n",
       "   '并不是什么都不想吃、不能吃，',\n",
       "   '而是TA吃了一个“空”。',\n",
       "   '这个“空”是由无意识、幻想所构建的，',\n",
       "   '是来源于重要养育人的话语下所构建的症状，',\n",
       "   '背后是一个幻想的支撑。',\n",
       "   '而心理咨询的工作，',\n",
       "   '就是陪伴您去穿越这个症状式的幻想，',\n",
       "   '达到主体生命的解放。',\n",
       "   '当然，',\n",
       "   '上面所提到的只是一点点理论，',\n",
       "   '同时标签也没有任何意义，',\n",
       "   '重要的是接受一段时间的心理咨询，',\n",
       "   '您会慢慢看到自己症状背后的幻想逻辑，',\n",
       "   '正是这些幻想导致减肥执念在不断重复。'],\n",
       "  ['千万不要节食，', '不要让自己处于饥饿的感觉中，', '平常感觉不饿就可以'],\n",
       "  ['听起来，',\n",
       "   '你在进食方面出现了困扰，',\n",
       "   '我想除了可能的心理原因之外，',\n",
       "   '但是进食问题会影响身体健康，',\n",
       "   '会影响你对食物的态度，',\n",
       "   '如果你有条件的话，',\n",
       "   '建议去当地医院看看专科医生，',\n",
       "   '一般进食问题药物治疗和心理治疗相结合更好，',\n",
       "   '也避免进食问题的进一步发展。']]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n = random.randint(0, total)\n",
    "\n",
    "it = FileInput(corpus_files)\n",
    "for i, line in tqdm(zip(range(n), it), total=n):\n",
    "    if i+1 < n:\n",
    "        continue\n",
    "    data = json.loads(line)\n",
    "    display(i)\n",
    "    display(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 按主题搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "试试看，指定一个标签，看看有多少个样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c912a7ed694c68ae18b4132ab5338a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=187156), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e697be740a49de8d43ac25a498c31a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=187156), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "主题 '婚姻' 数量: 31,760, 占比: 0.16969800594156748\n"
     ]
    }
   ],
   "source": [
    "topic = '婚姻'\n",
    "\n",
    "def filter_line_by_topic(line, topic):\n",
    "    line = line.strip()\n",
    "    if line:\n",
    "        sample = json.loads(line)\n",
    "        topics = sample.get('topics', [])\n",
    "        if topic in topics:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "it_lines = FileInput(corpus_files)\n",
    "with Pool() as pool:\n",
    "    it_map = pool.imap_unordered(\n",
    "        partial(filter_line_by_topic, topic=topic),\n",
    "        tqdm(it_lines, total=total),\n",
    "        chunksize=min(1024, total//os.cpu_count()+1)\n",
    "    )\n",
    "    it_map = tqdm(it_map, total=total)\n",
    "    c = sum(1 for x in it_map if x)\n",
    "\n",
    "print(f'主题 {topic!r} 数量: {c:,d}, 占比: {c/total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 样本选用和格式转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们应：\n",
    "\n",
    "- 选取问题+回答构成输入样本\n",
    "- 一个问题可以对应多个回答\n",
    "- 不要太短的\n",
    "- 不要太长的\n",
    "\n",
    "在此基础上，选用 `10,000` 个样本用于今次的开发"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 长短限制定义：\n",
    "\n",
    "MIN_QUESTION_LENGTH = 16\n",
    "MAX_QUESTION_LENGTH = 1024\n",
    "MIN_ANSWER_LENGTH = 32\n",
    "MAX_LENGTH = 2048\n",
    "\n",
    "\n",
    "def extract_samples(line):\n",
    "    line = line.strip()\n",
    "    if not line:\n",
    "        return []\n",
    "    data = json.loads(line)\n",
    "    result = []\n",
    "#     # 主题不对的不要！\n",
    "    topics = data.get('topics', []) \n",
    "#     if topic not in topics:\n",
    "#         return []\n",
    "#     # 没有主题的不要\n",
    "#     if not topics:\n",
    "#         return []\n",
    "    # 没有回答的不要\n",
    "    if not data.get('answers'):\n",
    "        return []\n",
    "    # 问题:\n",
    "    title = ''.join(data['title']).strip()\n",
    "#     # 没有标题的不要\n",
    "#     if not title:\n",
    "#         return []\n",
    "    text = ''.join(data['text']).strip()\n",
    "#     # 没有问题内容的不要\n",
    "#     if not text:\n",
    "#         return []\n",
    "    n_title = len(tokenizer.encode_as_ids(title))\n",
    "    n_text = len(tokenizer.encode_as_ids(text))\n",
    "    # 太短不要\n",
    "    if n_title + n_text < MIN_QUESTION_LENGTH:\n",
    "        return []\n",
    "    # 太长不要\n",
    "    if n_title + n_text > MAX_QUESTION_LENGTH:\n",
    "        return []\n",
    "    #\n",
    "    question_string = title + SEP + text\n",
    "    if topics:\n",
    "        question_string += SEP\n",
    "        for topic in topics:\n",
    "            question_string += CLS + topic.strip()\n",
    "    # 答案\n",
    "    for answer in data.get('answers', []):\n",
    "        text = ''.join(answer).strip()\n",
    "        length = len(tokenizer.encode_as_ids(text))\n",
    "        # 太短不要\n",
    "        if length < MIN_ANSWER_LENGTH:\n",
    "            continue\n",
    "        # 太长不要\n",
    "        if n_title + n_text + length > MAX_LENGTH:\n",
    "            continue\n",
    "        result.append(question_string + SEP*2 + text)\n",
    "    #\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用上一次随机取得的行试试看："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['因为减肥而带来心理疾病，该怎么办？<sep>可能从16岁开始吧，我就对减肥很执着，一直都在努力减肥，现在163/52kg想着继续减肥，继母家里的人从小都说我很胖，我心里很受打击，就一直在减肥，最近一年吧就开始发现自己心理好像越来越不正常了，吃饭的时候不敢吃，吃完了就很难过觉得自己会长胖，然后就进入了节食的状态，节食了两三天后又暴食，吃到胃很撑很难受的那种，然后心情就会很难过，很讨厌自己为什么吃这么多，不吃饭的时候自己也在反思说为什么要这样，为什么要节食，为什么要减肥现在很害怕吃东西，也很害怕看到食物，怕自己忍不住往嘴里塞东西，以前吃东西感觉到开心，现在不知道什么是开心，对什么事情都提不起兴趣，很不喜欢这样的自己，不知道该怎么办<sep><cls>人格特质<cls>情绪<cls>情绪调节<sep><sep>您好，看您的描述，已经不单只是减肥的问题了，应该属于临床上比较常见的体象障碍和神经性贪食、厌食症，建议到医院确诊一下，同时配合心理治疗，才有较好的效果。另外，神经症厌食在精神分析的理解框架下，并不是什么都不想吃、不能吃，而是TA吃了一个“空”。这个“空”是由无意识、幻想所构建的，是来源于重要养育人的话语下所构建的症状，背后是一个幻想的支撑。而心理咨询的工作，就是陪伴您去穿越这个症状式的幻想，达到主体生命的解放。当然，上面所提到的只是一点点理论，同时标签也没有任何意义，重要的是接受一段时间的心理咨询，您会慢慢看到自己症状背后的幻想逻辑，正是这些幻想导致减肥执念在不断重复。',\n",
       " '因为减肥而带来心理疾病，该怎么办？<sep>可能从16岁开始吧，我就对减肥很执着，一直都在努力减肥，现在163/52kg想着继续减肥，继母家里的人从小都说我很胖，我心里很受打击，就一直在减肥，最近一年吧就开始发现自己心理好像越来越不正常了，吃饭的时候不敢吃，吃完了就很难过觉得自己会长胖，然后就进入了节食的状态，节食了两三天后又暴食，吃到胃很撑很难受的那种，然后心情就会很难过，很讨厌自己为什么吃这么多，不吃饭的时候自己也在反思说为什么要这样，为什么要节食，为什么要减肥现在很害怕吃东西，也很害怕看到食物，怕自己忍不住往嘴里塞东西，以前吃东西感觉到开心，现在不知道什么是开心，对什么事情都提不起兴趣，很不喜欢这样的自己，不知道该怎么办<sep><cls>人格特质<cls>情绪<cls>情绪调节<sep><sep>听起来，你在进食方面出现了困扰，我想除了可能的心理原因之外，但是进食问题会影响身体健康，会影响你对食物的态度，如果你有条件的话，建议去当地医院看看专科医生，一般进食问题药物治疗和心理治疗相结合更好，也避免进食问题的进一步发展。']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_samples(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算全部样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a76c8f8662a4b6c9b902d6aee734995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='MAP', max=187156, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "676e7e53cd28478d9ef0cbdfe1722a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='RDC', max=187156, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "CPU times: user 5.48 s, sys: 2.69 s, total: 8.17 s\n",
      "Wall time: 8.8 s\n",
      "shuffle ...\n",
      "CPU times: user 280 ms, sys: 11 ms, total: 291 ms\n",
      "Wall time: 290 ms\n",
      "满足要求的样本数: 304,218\n"
     ]
    }
   ],
   "source": [
    "def generate_samples_from_corpus():\n",
    "    lines_iter = FileInput(corpus_files)\n",
    "    lines_iter = tqdm(lines_iter, desc='MAP', total=total)\n",
    "    with Pool() as pool:\n",
    "        mapping_iter = pool.imap_unordered(extract_samples, lines_iter, chunksize=min(1024, total//os.cpu_count())+1)\n",
    "        mapping_iter = tqdm(mapping_iter, desc='RDC', total=total)\n",
    "        yield from chain.from_iterable(mapping_iter)\n",
    "\n",
    "print('sample ...')        \n",
    "%time samples = list(generate_samples_from_corpus())\n",
    "\n",
    "print('shuffle ...')\n",
    "%time random.shuffle(samples)\n",
    "\n",
    "print(f'满足要求的样本数: {len(samples):,d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机显示一个:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总是多想<sep>我是一个很敏感的人，别人和我之间相处时发生的事，我却一直放不下，总是在多想，结果总是越想越焦躁。有时候明明只是一件小事，但我总是爱多想很久，很影响生活。心里烦闷的很，不知道怎么样才能让自己不多心多想放下这些事。<sep><cls>人格特质<cls>情绪<cls>焦虑<sep><sep>你好，不知道你多大了？看起来你对自己是有觉察的，敏感让你焦虑，并影响到了自己的生活和心情。你的敏感源于你内心的自卑，你能选择来这里求助，就非常的不简单。咨询是一个过程，我需要了解更多的情况，才能帮你分析解决问题。我帮助过很多和你一样困扰的人，相信也可以帮到你。可以多说一些你的情况吗？\n"
     ]
    }
   ],
   "source": [
    "s = random.choice(samples)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 采样并存储"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "划分为 train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集划分：\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 300000, 'val': 2000, 'test': 2000}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parts = {\n",
    "    'train': 300_000,\n",
    "    'val': 2_000,\n",
    "    'test': 2_000,\n",
    "}\n",
    "\n",
    "print('数据集划分：')\n",
    "display(parts)\n",
    "\n",
    "assert sum(parts.values()) <= len(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机种子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 270 ms, sys: 0 ns, total: 270 ms\n",
      "Wall time: 269 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "seeds = []\n",
    "seeds.extend(chain.from_iterable(\n",
    "    repeat(k, v) for k, v in parts.items()\n",
    "))\n",
    "seeds.extend(repeat(None, len(samples)-sum(parts.values())))\n",
    "random.shuffle(seeds)\n",
    "\n",
    "assert len(seeds) == len(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 输出文件路径\n",
    "\n",
    "保存为 NVIDIA/Megatron-LM 的 Loose Json 格式，使用 `\"text\"` 作为 Key。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出文件:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': '../data/xinliqa/xinliqa.train.json',\n",
       " 'val': '../data/xinliqa/xinliqa.val.json',\n",
       " 'test': '../data/xinliqa/xinliqa.test.json'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.08 ms, sys: 0 ns, total: 7.08 ms\n",
      "Wall time: 4.67 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# from slugify import slugify\n",
    "\n",
    "# topic_slug = slugify(topic, separator='')\n",
    "\n",
    "# output_files = {\n",
    "#     k: os.path.join('..', 'data', f'xinliqa_{topic_slug}.{k}.json')\n",
    "#     for k in part_num.keys()\n",
    "# }\n",
    "\n",
    "# print('输出文件:')\n",
    "# display(output_files)\n",
    "\n",
    "output_dir = '../data/xinliqa'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "output_files = {\n",
    "    k: os.path.join(output_dir, f'xinliqa.{k}.json')\n",
    "    for k in parts.keys()\n",
    "}\n",
    "\n",
    "print('输出文件:')\n",
    "display(output_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 写目标文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e970728b9264888b363dbc7299cea5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304218), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lines_iter = FileInput(corpus_files)\n",
    "\n",
    "with ExitStack() as stack:\n",
    "    files = {\n",
    "        k: stack.enter_context(open(v, 'w'))\n",
    "        for k, v in output_files.items()\n",
    "    }\n",
    "    for seed, string in tqdm(zip(seeds, samples), total=len(samples)):\n",
    "        fp = files.get(seed)\n",
    "        if not fp:\n",
    "            continue\n",
    "        print(\n",
    "            json.dumps({'text': string}, ensure_ascii=False),\n",
    "            file=fp\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查输出文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   300000 ../data/xinliqa/xinliqa.train.json\n",
      "     2000 ../data/xinliqa/xinliqa.val.json\n",
      "     2000 ../data/xinliqa/xinliqa.test.json\n",
      "   304000 总用量\n",
      "\n",
      "352M\t../data/xinliqa/xinliqa.train.json\n",
      "2.4M\t../data/xinliqa/xinliqa.val.json\n",
      "2.4M\t../data/xinliqa/xinliqa.test.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = ' '.join(output_files.values())\n",
    "\n",
    "!wc -l {s}\n",
    "print()\n",
    "\n",
    "!du -h {s}\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Megatron_LM-ipy]",
   "language": "python",
   "name": "conda-env-Megatron_LM-ipy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
