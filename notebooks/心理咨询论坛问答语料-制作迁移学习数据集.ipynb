{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 心理咨询论坛问答语料 - 制作迁徙学习数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为 NVIDIA/Megatron-LM 准备该领域的 finetune 数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 要点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用教少量的心理咨询论坛问答数据，在之前的泛情绪类预训练模型基础上进行 finetune\n",
    "- 使用特殊标记(Token) 分隔问题标题、文本、答案文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from copy import copy\n",
    "from contextlib import closing, ExitStack\n",
    "from functools import partial\n",
    "from glob import glob, iglob\n",
    "from itertools import chain, repeat\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用与 Pretrained-Model 同样的 tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spm_model_path = '../data/spm/gpt2_huamei_corpus_bpe_32k_v2.model'\n",
    "\n",
    "tokenizer = spm.SentencePieceProcessor()\n",
    "tokenizer.load(spm_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特殊标记\n",
    "\n",
    "该 Tokenizer 既有的特殊标记有："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <pad> True\n",
      "1 <unk> False\n",
      "2 <bos> True\n",
      "3 <eos> True\n",
      "4 <sep> False\n",
      "5 <cls> False\n",
      "6 <|endoftext|> False\n",
      "7 一个 False\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "  print(i, tokenizer.id_to_piece(i), tokenizer.is_control(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们选用：\n",
    "\n",
    "- 使用`id=4 <sep>` 表示问题部分中，标题与正文的分隔\n",
    "- 使用`id=6 <|endoftext|>` 表示问题结束\n",
    "- 使用 `id=2 <bos>` 表示回答的开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEP = tokenizer.id_to_piece(4)\n",
    "EOT = tokenizer.id_to_piece(6)\n",
    "BOS = tokenizer.id_to_piece(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_files = glob('/home/Public/data/transfer-learning/output/output-qa/xinli001_jiandanxinli-qa.topics/*.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "语料文件:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/Public/data/transfer-learning/output/output-qa/xinli001_jiandanxinli-qa.topics/valid_xinli_qax.json',\n",
       " '/home/Public/data/transfer-learning/output/output-qa/xinli001_jiandanxinli-qa.topics/train_xinli_qax.json',\n",
       " '/home/Public/data/transfer-learning/output/output-qa/xinli001_jiandanxinli-qa.topics/test_xinli_qax.json']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4866a5114d4a414b8e67ff661756d135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "总行数: 187,156\n"
     ]
    }
   ],
   "source": [
    "print('语料文件:')\n",
    "display(corpus_files)\n",
    "print()\n",
    "\n",
    "it = chain.from_iterable(map(open, corpus_files))\n",
    "total = sum(1 for _ in tqdm(it, unit='line'))\n",
    "\n",
    "print(f'总行数: {total:,d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在预览语料数据格式，随机选择一个："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d4924544c94083a5dfb4f5bc917818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18639), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'topics': ['治疗', '疾病诊断', '心理危机'],\n",
       " 'title': ['抑郁药吃过量的会死吗'],\n",
       " 'text': ['有一个人吃了三十多片多虑平 他会死吗 还是会昏睡几天 用不用医院 洗胃后会不会留下后遗症'],\n",
       " 'answers': [['你想试试，', '可以先找好医院再试，', '如果愿意可以选择咨询。']]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = random.randint(0, total)\n",
    "\n",
    "it = chain.from_iterable(map(open, corpus_files))\n",
    "it = enumerate(it)\n",
    "for i, line in tqdm(it, total=n):\n",
    "    if i < n:\n",
    "        continue\n",
    "    data = json.loads(line)\n",
    "    display(data)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 样本选用和格式转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们应：\n",
    "\n",
    "- 选取问题+回答构成输入样本\n",
    "- 一个问题可以对应多个回答\n",
    "- 不要太短的\n",
    "- 不要太长的\n",
    "\n",
    "在此基础上，选用 `10,000` 个样本用于今次的开发"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### 长短限制定义：\n",
    "\n",
    "MIN_QUESTION_LENGTH = 16\n",
    "MAX_QUESTION_LENGTH = 512\n",
    "MIN_ANSWER_LENGTH = 32\n",
    "MAX_LENGTH = 1024+128\n",
    "\n",
    "\n",
    "def extract_samples(line):\n",
    "    line = line.strip()\n",
    "    if not line:\n",
    "        return []\n",
    "    data = json.loads(line)\n",
    "    result = []\n",
    "    # 没有回答的不要\n",
    "    if not data.get('answers'):\n",
    "        return []\n",
    "    # 问题:\n",
    "    title = ''.join(data['title']).strip()\n",
    "    # 没有标题的不要\n",
    "    if not title:\n",
    "        return []\n",
    "    text = ''.join(data['text']).strip()\n",
    "    # 没有问题内容的不要\n",
    "    if not text:\n",
    "        return []\n",
    "    n_title = len(tokenizer.encode_as_ids(title))\n",
    "    n_text = len(tokenizer.encode_as_ids(text))\n",
    "    # 太短不要\n",
    "    if n_title + n_text < MIN_QUESTION_LENGTH:\n",
    "        return []\n",
    "    # 太长不要\n",
    "    if n_title + n_text > MAX_QUESTION_LENGTH:\n",
    "        return []\n",
    "    #\n",
    "    question_string = title + SEP + text + EOT\n",
    "    # 答案\n",
    "    for answer in data.get('answers', []):\n",
    "        text = ''.join(answer).strip()\n",
    "        length = len(tokenizer.encode_as_ids(text))\n",
    "        # 太短不要\n",
    "        if length < MIN_ANSWER_LENGTH:\n",
    "            continue\n",
    "        # 太长不要\n",
    "        if n_title + n_text + length > MAX_LENGTH:\n",
    "            continue\n",
    "        result.append(question_string + BOS + text)\n",
    "    #\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用上一次随机取得的行试试看："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_samples(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算全部样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d4129da6864a8e8acce946e1ea0bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='MAP', max=187156, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ecc7489ce4c4eb28c06b76603184af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='RDC', max=187156, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "满足要求的样本数: 220,840\n"
     ]
    }
   ],
   "source": [
    "def generate_samples_from_corpus():\n",
    "    lines_iter = chain.from_iterable(map(open, corpus_files))\n",
    "    lines_iter = tqdm(lines_iter, desc='MAP', total=total)\n",
    "    with Pool() as pool:\n",
    "        mapping_iter = pool.imap_unordered(extract_samples, lines_iter)\n",
    "        mapping_iter = tqdm(mapping_iter, desc='RDC', total=total)\n",
    "        yield from chain.from_iterable(mapping_iter)\n",
    "\n",
    "samples = []\n",
    "for sample in generate_samples_from_corpus():\n",
    "    samples.append(sample)\n",
    "\n",
    "print(f'满足要求的样本数: {len(samples):,d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机显示一个:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "毕业找工作和考国网<sep>我大学学的专业是绝缘与电缆，这个专业就业面窄，也就是去电缆厂做技术员，实习一次后，觉得不适应这种工作，打算考国网，因为学校不是重点，考上了基本也就是去县局，现在很迷茫，不知道该往哪个方向走～<|endoftext|><bos>能找到工作，能养活自己就是好样的要想挑肥拣瘦的话，要么退回高考，考个好学校再选个好专业，要么靠自己毕业后去创业去奋斗\n"
     ]
    }
   ],
   "source": [
    "n = random.randint(0, len(samples))\n",
    "s = samples[n]\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 采样并存储"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "划分为 train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集划分：\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 200000, 'val': 1000, 'test': 1000}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "part_num = {\n",
    "    'train': 200000,\n",
    "    'val': 1000,\n",
    "    'test': 1000,\n",
    "}\n",
    "\n",
    "print('数据集划分：')\n",
    "display(part_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机种子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 177 ms, sys: 0 ns, total: 177 ms\n",
      "Wall time: 176 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "seeds = []\n",
    "seeds.extend(chain.from_iterable(\n",
    "    repeat(k, v) for k, v in part_num.items()\n",
    "))\n",
    "seeds.extend(repeat(None, len(samples)-sum(part_num.values())))\n",
    "random.shuffle(seeds)\n",
    "\n",
    "assert len(seeds) == len(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存为 NVIDIA/Megatron-LM 的 Loose Json 格式，使用 `\"text\"` 作为 Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出文件:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': '../data/xinliqa_191030.train.json',\n",
       " 'val': '../data/xinliqa_191030.val.json',\n",
       " 'test': '../data/xinliqa_191030.test.json'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ffdf376e9c44ec894f364683c384ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=220840), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 3.37 s, sys: 511 ms, total: 3.88 s\n",
      "Wall time: 4.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "output_files = {\n",
    "    k: os.path.join('..', 'data', f'xinliqa_191030.{k}.json')\n",
    "    for k in part_num.keys()\n",
    "}\n",
    "\n",
    "print('输出文件:')\n",
    "display(output_files)\n",
    "\n",
    "lines_iter = chain.from_iterable(map(open, corpus_files))\n",
    "\n",
    "with ExitStack() as stack:\n",
    "    files = {\n",
    "        k: stack.enter_context(open(v, 'w'))\n",
    "        for k, v in output_files.items()\n",
    "    }\n",
    "    for seed, string in tqdm(zip(seeds, samples), total=len(samples)):\n",
    "        fp = files.get(seed)\n",
    "        if not fp:\n",
    "            continue\n",
    "        print(\n",
    "            json.dumps({'text': string}, ensure_ascii=False),\n",
    "            file=fp\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   200000 ../data/xinliqa_191030.train.json\n",
      "     1000 ../data/xinliqa_191030.val.json\n",
      "     1000 ../data/xinliqa_191030.test.json\n",
      "   202000 总用量\n",
      "\n",
      "243M\t../data/xinliqa_191030.train.json\n",
      "1.3M\t../data/xinliqa_191030.val.json\n",
      "1.3M\t../data/xinliqa_191030.test.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = ' '.join(output_files.values())\n",
    "\n",
    "!wc -l {s}\n",
    "print()\n",
    "\n",
    "!du -h {s}\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Megatron_LM-ipy]",
   "language": "python",
   "name": "conda-env-Megatron_LM-ipy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
