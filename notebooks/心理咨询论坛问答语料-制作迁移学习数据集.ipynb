{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 心理咨询论坛问答语料 - 制作迁徙学习数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为 NVIDIA/Megatron-LM 准备该领域的 finetune 数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 要点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用教少量的心理咨询论坛问答数据，在之前的泛情绪类预训练模型基础上进行 finetune\n",
    "- 使用特殊标记(Token) 分隔问题标题、文本、答案文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from copy import copy\n",
    "from contextlib import closing, ExitStack\n",
    "from functools import partial\n",
    "from glob import glob, iglob\n",
    "from fileinput import FileInput\n",
    "from itertools import chain, repeat\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用与 Pretrained-Model 同样的 tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spm_model_path = '../data/spm/gpt2_huamei_corpus_bpe_32k_v2.model'\n",
    "\n",
    "tokenizer = spm.SentencePieceProcessor()\n",
    "tokenizer.load(spm_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特殊标记\n",
    "\n",
    "该 Tokenizer 既有的特殊标记有："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <pad> True\n",
      "1 <unk> False\n",
      "2 <bos> True\n",
      "3 <eos> True\n",
      "4 <sep> False\n",
      "5 <cls> False\n",
      "6 <|endoftext|> False\n",
      "7 一个 False\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "  print(i, tokenizer.id_to_piece(i), tokenizer.is_control(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们选用：\n",
    "\n",
    "- 使用`id=4 <sep>` 表示问题部分中，标题与正文的分隔\n",
    "- 使用`id=6 <|endoftext|>` 表示问题结束\n",
    "- 使用 `id=2 <bos>` 表示回答的开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEP = tokenizer.id_to_piece(4)\n",
    "EOT = tokenizer.id_to_piece(6)\n",
    "BOS = tokenizer.id_to_piece(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_files = glob('/home/Public/data/transfer-learning/output/output-qa/xinli001_jiandanxinli-qa.topics/*.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "语料文件:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/Public/data/transfer-learning/output/output-qa/xinli001_jiandanxinli-qa.topics/valid_xinli_qax.json',\n",
       " '/home/Public/data/transfer-learning/output/output-qa/xinli001_jiandanxinli-qa.topics/train_xinli_qax.json',\n",
       " '/home/Public/data/transfer-learning/output/output-qa/xinli001_jiandanxinli-qa.topics/test_xinli_qax.json']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed57192273a445aa6731b10f6f6ddd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "总行数: 187,156\n"
     ]
    }
   ],
   "source": [
    "print('语料文件:')\n",
    "display(corpus_files)\n",
    "print()\n",
    "\n",
    "it = FileInput(corpus_files)\n",
    "total = sum(1 for _ in tqdm(it, unit='line'))\n",
    "\n",
    "print(f'总行数: {total:,d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在预览语料数据格式，随机选择一个："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec7e25d9088f4aa0ae349b6a2cba4c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=122731), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'topics': ['恋爱', '出轨', '依赖依恋', '安全感'],\n",
       " 'title': ['23岁女，看见有人向男友表白，不知道该不该怀疑他？'],\n",
       " 'text': ['一个月前，在男友微信上看见有人跟他表白，看见聊天记录上那个人一直找他聊天，男友也会偶尔会回复一下，但聊的不是很多。',\n",
       "  '但是后面就看见那个人跟他表白了，但是男友也没有拒绝的很明显，甚至没有表明自己有女朋友的这件事，询问后他解释说他们什么都没有，他也不喜欢他，也答应我说不会和她再聊天了。',\n",
       "  '但是也改了手机密码，我不知道我是不是该怀疑他，他会出轨吗？'],\n",
       " 'answers': [['对方会不会出轨这是难以预见的，',\n",
       "   '仅仅这样的情况就判断会不会出轨那是言之过早。',\n",
       "   '不管你选择相信还是怀疑，',\n",
       "   '都需要对自己的选择负责。'],\n",
       "  ['朋友你好，',\n",
       "   '看到你的描述，',\n",
       "   '大致了解到情况。',\n",
       "   '不过在分析之前，',\n",
       "   '我想先说明一点，',\n",
       "   '我不能改变你的选择，',\n",
       "   '我也不能够预知未来你的男友会不会出轨。',\n",
       "   '我能够给你的是一个考虑这个问题，',\n",
       "   '看待这个问题的角度。',\n",
       "   '从你的描述中来看，',\n",
       "   '你是一个理智且有包容心的人，',\n",
       "   '看到有人和自己的男友聊天甚至有想要告白的企图，',\n",
       "   '仍然可以好好说话，',\n",
       "   '听男友的解释而不是大闹特闹，',\n",
       "   '让男友把女孩的微信删掉。',\n",
       "   '你并没有过多的干涉，',\n",
       "   '这一点你处理地很好。',\n",
       "   '给男友交友空间，',\n",
       "   '并且愿意开诚布公聊这件事。',\n",
       "   '另外你说到男友把手机密码改了，',\n",
       "   '这一点我觉得是正常的，',\n",
       "   '为啥这么说呢？',\n",
       "   '因为现代社会，',\n",
       "   '手机可以说是带锁的密码本，',\n",
       "   '什么事情都可以在手机里找到答案，',\n",
       "   '也很有可能过度解读一些事情。',\n",
       "   '每个人都有保留自己的权利，',\n",
       "   '人的两大基本需要亲密和自主。',\n",
       "   '你的男友从你这里得到亲密，',\n",
       "   '但他仍然有自主的权利。',\n",
       "   '当然你也有，',\n",
       "   '你可以选择怀疑他，',\n",
       "   '强迫他把手机密码改回来，',\n",
       "   '但你已经伤害到他的自主，',\n",
       "   '关系收到了损害。',\n",
       "   '得不偿失。',\n",
       "   '最后我想分享给你一把人际关系的金钥匙尊重他人也尊重自己，',\n",
       "   '为什么把尊重他人放在第一位呢，',\n",
       "   '因为在交往过程中，',\n",
       "   '我们能够选择的只有自己的方式，',\n",
       "   '先尊重他人，',\n",
       "   '他人才更有可能尊重你想尊重自己的想法。',\n",
       "   '祝好']]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = random.randint(0, total)\n",
    "\n",
    "it = enumerate(FileInput(corpus_files))\n",
    "for i, line in tqdm(it, total=n):\n",
    "    if i < n:\n",
    "        continue\n",
    "    data = json.loads(line)\n",
    "    display(data)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 按主题搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "试试看，指定一个标签，看看有多少个样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c912a7ed694c68ae18b4132ab5338a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=187156), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e697be740a49de8d43ac25a498c31a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=187156), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "主题 '婚姻' 数量: 31,760, 占比: 0.16969800594156748\n"
     ]
    }
   ],
   "source": [
    "topic = '婚姻'\n",
    "\n",
    "def filter_line_by_topic(line, topic):\n",
    "    line = line.strip()\n",
    "    if line:\n",
    "        sample = json.loads(line)\n",
    "        topics = sample.get('topics', [])\n",
    "        if topic in topics:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "it_lines = FileInput(corpus_files)\n",
    "with Pool() as pool:\n",
    "    it_map = pool.imap_unordered(\n",
    "        partial(filter_line_by_topic, topic=topic),\n",
    "        tqdm(it_lines, total=total),\n",
    "        chunksize=min(1024, total//os.cpu_count()+1)\n",
    "    )\n",
    "    it_map = tqdm(it_map, total=total)\n",
    "    c = sum(1 for x in it_map if x)\n",
    "\n",
    "print(f'主题 {topic!r} 数量: {c:,d}, 占比: {c/total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 样本选用和格式转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们应：\n",
    "\n",
    "- 选取问题+回答构成输入样本\n",
    "- 一个问题可以对应多个回答\n",
    "- 不要太短的\n",
    "- 不要太长的\n",
    "\n",
    "在此基础上，选用 `10,000` 个样本用于今次的开发"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 长短限制定义：\n",
    "\n",
    "MIN_QUESTION_LENGTH = 16\n",
    "MAX_QUESTION_LENGTH = 512\n",
    "MIN_ANSWER_LENGTH = 32\n",
    "MAX_LENGTH = 1024+128\n",
    "\n",
    "\n",
    "def extract_samples(line):\n",
    "    line = line.strip()\n",
    "    if not line:\n",
    "        return []\n",
    "    data = json.loads(line)\n",
    "    result = []\n",
    "    # 主题不对的不要！\n",
    "    topics = data.get('topics', [])\n",
    "    if topic not in topics:\n",
    "        return []\n",
    "    # 没有回答的不要\n",
    "    if not data.get('answers'):\n",
    "        return []\n",
    "    # 问题:\n",
    "    title = ''.join(data['title']).strip()\n",
    "    # 没有标题的不要\n",
    "    if not title:\n",
    "        return []\n",
    "    text = ''.join(data['text']).strip()\n",
    "    # 没有问题内容的不要\n",
    "    if not text:\n",
    "        return []\n",
    "    n_title = len(tokenizer.encode_as_ids(title))\n",
    "    n_text = len(tokenizer.encode_as_ids(text))\n",
    "    # 太短不要\n",
    "    if n_title + n_text < MIN_QUESTION_LENGTH:\n",
    "        return []\n",
    "    # 太长不要\n",
    "    if n_title + n_text > MAX_QUESTION_LENGTH:\n",
    "        return []\n",
    "    #\n",
    "    question_string = title + SEP + text + EOT\n",
    "    # 答案\n",
    "    for answer in data.get('answers', []):\n",
    "        text = ''.join(answer).strip()\n",
    "        length = len(tokenizer.encode_as_ids(text))\n",
    "        # 太短不要\n",
    "        if length < MIN_ANSWER_LENGTH:\n",
    "            continue\n",
    "        # 太长不要\n",
    "        if n_title + n_text + length > MAX_LENGTH:\n",
    "            continue\n",
    "        result.append(question_string + BOS + text)\n",
    "    #\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用上一次随机取得的行试试看："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_samples(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算全部样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e91e9dd63e4943bff8fcb7caf2fc13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='MAP', max=187156, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5781434ec63a4477a4c149f0fd659300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='RDC', max=187156, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "满足要求的样本数: 24,768\n"
     ]
    }
   ],
   "source": [
    "def generate_samples_from_corpus():\n",
    "    lines_iter = FileInput(corpus_files)\n",
    "    lines_iter = tqdm(lines_iter, desc='MAP', total=total)\n",
    "    with Pool() as pool:\n",
    "        mapping_iter = pool.imap_unordered(extract_samples, lines_iter, chunksize=min(1024, total//os.cpu_count())+1)\n",
    "        mapping_iter = tqdm(mapping_iter, desc='RDC', total=total)\n",
    "        yield from chain.from_iterable(mapping_iter)\n",
    "\n",
    "samples = []\n",
    "for sample in generate_samples_from_corpus():\n",
    "    samples.append(sample)\n",
    "\n",
    "print(f'满足要求的样本数: {len(samples):,d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机显示一个:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "老婆单位受气，容易找我撒气，我该如何处理为好？<sep>老婆在单位和直接领导做事想法、方式差异较大，看不顺眼，负面情绪容易带到家里，拿我撒气，开始我不清楚，拿来撒气的小事会辩解，惹来更大的脾气就会觉得很无语，后来细想后有些了解了，也就不做啥辩解了，但是是否有好点的处理方法呢？家里可否少些这种情绪宣泄？<|endoftext|><bos>人在熟悉安全的环境才会释放自我，很明显你老婆找你撒气，是希望得到你的关注，认同，理解她。和她站在一条战线上。发脾气，生气，这是我们每个人都会有的体验和经历，它是一种硬情绪，是自我保护的一种方式。在生气、愤怒的背后往往隐藏着软情绪，比如悲伤、失落，这些是我们内在的脆弱，是不太愿意被别人看到的部分，所以往往会通过发脾气的方式来表达不满，而更深层次的原因是我们感觉到没有被看见、被尊重、被支持、被关爱、被认可。在这世界上，没有人想给别人惹麻烦，想惹别人生气。如果你认识到每个人都是从自己的角度来解读世界，每一个愤怒、发脾气、生气的背后，都是对爱的呼唤，就能更容易理解别人了。情绪如何处理为好？如果你能够理解，你就多帮帮她说话，站在她那边，替她想一想。看看能不能给出一些建议。其实情绪会告诉我们一些什么，每个情绪都是我们的朋友。1、给情绪命名。能够给情绪命名，就能化解情绪。感受一下自己或她的情绪，确定自己或她的情绪是生气、愤怒、还是烦躁，然后告诉自己我此刻很怎么样。比如生气2、（情绪的核心）我真正的需求是什么。继续保持深呼吸，和自己对话：我到底为什么生气，我真正需要的是什么，是因为我不被尊重？不被重视？不被理解？不被关爱？还是自己的悲伤、失落、恐惧等情绪干扰了我的心智？到底什么是真相，到底什么是我真正的需求？3、有时间就接你老婆下班，如果她有情绪可以陪她在外面喊山或其它方式来减压，发泄完了再回家，这样可以减少在家宣泄情绪。当然如果你有时间可以把家里的卫生打扫一下，把东西摆放整齐，当她看到家里干净的环境，也会让她有一个好的心情。\n"
     ]
    }
   ],
   "source": [
    "s = random.choice(samples)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 采样并存储"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "划分为 train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集划分：\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 20000, 'val': 1000, 'test': 1000}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "part_num = {\n",
    "    'train': 20000,\n",
    "    'val': 1000,\n",
    "    'test': 1000,\n",
    "}\n",
    "\n",
    "print('数据集划分：')\n",
    "display(part_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机种子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.1 ms, sys: 648 µs, total: 19.8 ms\n",
      "Wall time: 18.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "seeds = []\n",
    "seeds.extend(chain.from_iterable(\n",
    "    repeat(k, v) for k, v in part_num.items()\n",
    "))\n",
    "seeds.extend(repeat(None, len(samples)-sum(part_num.values())))\n",
    "random.shuffle(seeds)\n",
    "\n",
    "assert len(seeds) == len(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存为 NVIDIA/Megatron-LM 的 Loose Json 格式，使用 `\"text\"` 作为 Key。\n",
    "\n",
    "计算文件路径名："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出文件:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': '../data/xinliqa_hunyin.train.json',\n",
       " 'val': '../data/xinliqa_hunyin.val.json',\n",
       " 'test': '../data/xinliqa_hunyin.test.json'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.78 ms, sys: 822 µs, total: 3.6 ms\n",
      "Wall time: 2.21 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from slugify import slugify\n",
    "\n",
    "topic_slug = slugify(topic, separator='')\n",
    "\n",
    "output_files = {\n",
    "    k: os.path.join('..', 'data', f'xinliqa_{topic_slug}.{k}.json')\n",
    "    for k in part_num.keys()\n",
    "}\n",
    "\n",
    "print('输出文件:')\n",
    "display(output_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出到目标文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81447f2599e445108c44dc328a210069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=24768), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lines_iter = FileInput(corpus_files)\n",
    "\n",
    "with ExitStack() as stack:\n",
    "    files = {\n",
    "        k: stack.enter_context(open(v, 'w'))\n",
    "        for k, v in output_files.items()\n",
    "    }\n",
    "    for seed, string in tqdm(zip(seeds, samples), total=len(samples)):\n",
    "        fp = files.get(seed)\n",
    "        if not fp:\n",
    "            continue\n",
    "        print(\n",
    "            json.dumps({'text': string}, ensure_ascii=False),\n",
    "            file=fp\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查输出文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   20000 ../data/xinliqa_hunyin.train.json\n",
      "    1000 ../data/xinliqa_hunyin.val.json\n",
      "    1000 ../data/xinliqa_hunyin.test.json\n",
      "   22000 总用量\n",
      "\n",
      "25M\t../data/xinliqa_hunyin.train.json\n",
      "1.3M\t../data/xinliqa_hunyin.val.json\n",
      "1.3M\t../data/xinliqa_hunyin.test.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = ' '.join(output_files.values())\n",
    "\n",
    "!wc -l {s}\n",
    "print()\n",
    "\n",
    "!du -h {s}\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Megatron_LM-ipy]",
   "language": "python",
   "name": "conda-env-Megatron_LM-ipy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
