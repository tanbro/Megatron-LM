{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 心理咨询论坛问答语料(无标签平面文本) - 制作迁徙学习数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为 NVIDIA/Megatron-LM 准备该领域的 finetune 数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 用问题与其多个答案中的一个反复组合，形成多个问题-答案对\n",
    "- 使用 tag 或者问题中的关键字，选取一个类型的问答数据作为语料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "来源语料格式举例：\n",
    "\n",
    "```json\n",
    "{'topics': ['婚姻'],\n",
    " 'title': [],\n",
    " 'text': ['其实无论我们遇见谁和谁相恋，无论成功与否都是过程和经历，即便是失败也不要沮丧，我们要回头在那失败的地方我们学到了什么，并且有什么美好的回忆留在心里，在人生道路上，只要我们认真对待感情，正正经经的恋爱，就算被辜负或者遇见错的人而失望，但我相信认真对待生活的人一定会有收获的，再困难再痛苦事情都会过去的，你依然是你，天也不会塌，经历会让我们成长，更懂得生活的意义，才会有精彩的人生。',\n",
    "  '会有那么一个人会看见你的内在，拥抱你真挚的心。',\n",
    "  '我说的对么?'],\n",
    " 'answers': [['是的，', '做好自己，', '勇敢面对一切快乐和痛苦，', '一切源于我们的内心，', '修炼自己']]}\n",
    "```\n",
    "\n",
    "形成的平面带有分隔符的QA语料是：\n",
    "\n",
    "```js\n",
    "    plain_text(title) + \"<sep>\"\n",
    "  + plain_text(text) + plain_text(slave_text) + \"<sep>\"\n",
    "  + \"<sep>\"\n",
    "  + \"<|endoftext|>\" + plain_text(answer)\n",
    "```\n",
    "\n",
    "将输出的语料存放在 JSON Lines 文件中，文本内容放在 `text` 属性中\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CD\n",
    "\n",
    "切换到工作目录(**按实际情况，勿照搬下面的 Cell**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/Public/Megatron-LM\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from copy import copy\n",
    "from contextlib import closing, ExitStack\n",
    "import fileinput\n",
    "from functools import partial\n",
    "from glob import glob, iglob\n",
    "from itertools import chain, repeat\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "from tqdm.auto import tqdm, trange\n",
    "from slugify import slugify\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用与 Pretrained-Model 同样的 tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentencePiece 内置的特殊标记:\n",
      "0 <pad> True\n",
      "1 <unk> False\n",
      "2 <bos> True\n",
      "3 <eos> True\n",
      "4 <sep> False\n",
      "5 <cls> False\n",
      "6 <|endoftext|> False\n",
      "7 一个 False\n",
      "\n",
      "Wrapped tokenizer ...\n",
      "0: <pad>\n",
      "1: <eos>\n",
      "2: <bos>\n",
      "3: <unk>\n",
      "4: <sep>\n",
      "5: <L2R>\n",
      "6: <ENC>\n",
      "7: <MASK>\n",
      "CPU times: user 892 ms, sys: 108 ms, total: 1 s\n",
      "Wall time: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from data_utils.tokenization import SentencePieceTokenizer, make_tokenizer\n",
    "\n",
    "\n",
    "TOKENIZER_MODEL_PATH='./data/spm/gpt2_huamei_corpus_bpe_32k_v2.model'\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(TOKENIZER_MODEL_PATH)\n",
    "\n",
    "print('SentencePiece 内置的特殊标记:')\n",
    "for i in range(8):\n",
    "  print(i, sp.id_to_piece(i), sp.is_control(i))\n",
    "del sp\n",
    "print()\n",
    "\n",
    "print('Wrapped tokenizer ...')\n",
    "tokenizer = make_tokenizer(\n",
    "    SentencePieceTokenizer,\n",
    "    None,\n",
    "    model_path=TOKENIZER_MODEL_PATH\n",
    ")\n",
    "\n",
    "# tokenizer.command_tokens\n",
    "for tok in tokenizer.command_name_map.values():\n",
    "    print(f'{tok.Id}: {tok.token}')\n",
    "\n",
    "# 需要的特殊标记：\n",
    "SEP = '<sep>'\n",
    "START_OF_ANSWER = '<|endoftext|>'\n",
    "\n",
    "for piece in (SEP, START_OF_ANSWER):\n",
    "    assert piece == tokenizer.IdToToken(tokenizer.TokenToId(piece))\n",
    "    assert piece == tokenizer.IdToToken(tokenizer.EncodeAsIds(piece).tokenization[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3111321f9a4f8db2d0608c0e533818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d269e65f88c3470e82aad286b3e09cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cde784061e64fb88d6bb5622875db29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "语料文件:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': {'fp': '/home/Public/data/transfer-learning/output/output-qa/xinli001_jiandanxinli-qa.topics/train_xinli_qax.json',\n",
       "  'lc': 166941},\n",
       " 'val': {'fp': '/home/Public/data/transfer-learning/output/output-qa/xinli001_jiandanxinli-qa.topics/valid_xinli_qax.json',\n",
       "  'lc': 9172},\n",
       " 'test': {'fp': '/home/Public/data/transfer-learning/output/output-qa/xinli001_jiandanxinli-qa.topics/test_xinli_qax.json',\n",
       "  'lc': 7339}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_files = {\n",
    "    'train': {\n",
    "        'fp': '/home/Public/data/transfer-learning/output/output-qa/xinli001_jiandanxinli-qa.topics/train_xinli_qax.json'\n",
    "    },\n",
    "    'val': {\n",
    "        'fp': '/home/Public/data/transfer-learning/output/output-qa/xinli001_jiandanxinli-qa.topics/valid_xinli_qax.json'   \n",
    "    },\n",
    "    'test': {\n",
    "        'fp': '/home/Public/data/transfer-learning/output/output-qa/xinli001_jiandanxinli-qa.topics/test_xinli_qax.json'  \n",
    "    },\n",
    "}\n",
    "\n",
    "# 计算行数\n",
    "for data in src_files.values():\n",
    "    with open(data['fp']) as fp:\n",
    "        data['lc'] = sum(1 for _ in tqdm(fp))\n",
    "\n",
    "print('语料文件:')\n",
    "display(src_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在预览语料数据格式，随机选择一个："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423099b3e09f45b29caf246726e0b0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3810), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3809"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'topics': ['成长'],\n",
       " 'title': ['如何改变自己的性格'],\n",
       " 'text': ['我是一个很敏感，很懦弱，很胆小，很内向的人。',\n",
       "  '这样的性格从小到大陪伴着我，从小学到高中，从大学到现在毕业半年，不曾有过什么变化。',\n",
       "  '家里的亲戚对我的评价最多的就是“这孩子咋不吱声啊？',\n",
       "  '这孩子怎么一句话不说啊？',\n",
       "  '这孩子咋这么老实啊？”在学校的时候我就是这样一个不爱说话的人，跟班里的同学几乎没怎么说过话，没什么朋友，别人下课在聊天的时候而我一直都是一个人在那里坐着，我可以一天不说话，也没有人搭理我。',\n",
       "  '那个时候我盼着上大学，我可以在大学里面改变自己。',\n",
       "  '后来我上了大学，大学里有好多事情想做却都没有做，四年很快过去了，我还是没有什么变化，我还是这样。',\n",
       "  '过年回家了，亲戚们在一起吃饭的时候还会说“这孩子怎么还是不说话啊？',\n",
       "  '这孩子咋还不吱声啊？”一直到现在，我现在开始怀疑我是不是心理有问题，我到底应该怎么做才能改变我的性格？'],\n",
       " 'answers': [['为何你觉得你有心理问题呢？', '为何你觉得你的性格需要改呢？'],\n",
       "  ['恩，',\n",
       "   '你这样哦，',\n",
       "   '是不是和你小的时候成长环境有关呢？',\n",
       "   '想一想自己为什么会这样呢，',\n",
       "   '是因为害怕么，',\n",
       "   '天性么，',\n",
       "   '喜欢这样么？',\n",
       "   '改变性格，',\n",
       "   '是可以做到的，',\n",
       "   '我之前也想你这样，',\n",
       "   '那是因为我自卑，',\n",
       "   '我害怕，',\n",
       "   '我不敢与别人交谈，',\n",
       "   '当然这跟我的成长环境有关，',\n",
       "   '但是后来，',\n",
       "   '我结交了一些朋友还有老师也倾听我的心事，',\n",
       "   '一直在默默的帮我，',\n",
       "   '要说我怎么转变的啊，',\n",
       "   '是因为我爸爸去世了，',\n",
       "   '恩，',\n",
       "   '我就长大了一些，',\n",
       "   '然后自我意识的不断完善，',\n",
       "   '我就反抗的越来越强烈，',\n",
       "   '要看个人意识吧，',\n",
       "   '有一天我成功了，',\n",
       "   '我不记得那是第几次对着妈妈又哭又吼，',\n",
       "   '跟他说我这十多年来有多难过，',\n",
       "   '她听了后，',\n",
       "   '眼睛湿了，',\n",
       "   '他对我说了一句“妈妈知道错了，',\n",
       "   '我知道我之前对你的方式有多么错误。”就这一句话，',\n",
       "   '我听完后就觉得压在心里十多年的石头终于被击碎了，',\n",
       "   '我终于不再缅怀这些事了，',\n",
       "   '我终于放下了。',\n",
       "   '其实还是自己好好想想，',\n",
       "   '我到底为什么会这样呢？',\n",
       "   '想清楚了，',\n",
       "   '就开始想解决方法吧。',\n",
       "   '抱抱你哦，',\n",
       "   '看到你这样就像看到当年的的我，',\n",
       "   '我可以，',\n",
       "   '我相信你也可以的，',\n",
       "   '相信你自己，',\n",
       "   '你可以变成你想要成为的那个人的！']],\n",
       " 'likes': [0, 0],\n",
       " 'comments': [0, 0],\n",
       " 'answers_num': 2}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n = random.randint(0, src_files['test']['lc'])\n",
    "\n",
    "with open(src_files['test']['fp']) as fp:\n",
    "    for i, line in tqdm(zip(range(n), fp), total=n):\n",
    "        if i+1 < n:\n",
    "            continue\n",
    "        data = json.loads(line)\n",
    "        display(i)\n",
    "        display(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### 采样条件\n",
    "\n",
    "我们应：\n",
    "\n",
    "- 选取问题+回答构成输入样本\n",
    "- 一个问题可以对应多个回答\n",
    "- 不要太短的\n",
    "- 不要太长的\n",
    "- 指定的主题\n",
    "\n",
    "在此基础上，随机乱序选用若干样本用于今次的开发"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 主题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC = '婚姻'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 长度限制定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_QUESTION_LENGTH = 16\n",
    "MAX_QUESTION_LENGTH = 1024\n",
    "MIN_ANSWER_LENGTH = 32\n",
    "MAX_LENGTH = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 样本过滤函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_samples(line):\n",
    "    line = line.strip()\n",
    "    if not line:\n",
    "        return []\n",
    "    data = json.loads(line)\n",
    "    result = []\n",
    "#     # 主题不对的不要！\n",
    "    topics = data.get('topics', []) \n",
    "    if TOPIC not in topics:\n",
    "        return []\n",
    "    # 没有回答的不要\n",
    "    if not data.get('answers'):\n",
    "        return []\n",
    "    # 问题:\n",
    "    title = ''.join(data['title']).strip()\n",
    "    text = ''.join(data['text']).strip()\n",
    "    # 既没有问题标题又没有问题内容的不要\n",
    "    if not title and not text:\n",
    "        return []\n",
    "    n_title = len(tokenizer.EncodeAsIds(title))\n",
    "    n_text = len(tokenizer.EncodeAsIds(text))\n",
    "    # 太短不要\n",
    "    if n_title + n_text < MIN_QUESTION_LENGTH:\n",
    "        return []\n",
    "    # 太长不要\n",
    "    if n_title + n_text > MAX_QUESTION_LENGTH:\n",
    "        return []\n",
    "    # 回答：\n",
    "    question_string = title + SEP + text + SEP\n",
    "    # 答案\n",
    "    for answer in data.get('answers', []):\n",
    "        text = ''.join(answer).strip()\n",
    "        length = len(tokenizer.EncodeAsIds(text))\n",
    "        # 太短不要\n",
    "        if length < MIN_ANSWER_LENGTH:\n",
    "            continue\n",
    "        # 太长不要\n",
    "        if n_title + n_text + length > MAX_LENGTH:\n",
    "            continue\n",
    "        result.append(question_string + SEP + START_OF_ANSWER + text)\n",
    "    #\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 进行采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6bbbcd1dc424b10a600eedcc6228c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=166941), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df62f40e031248feba86246f81bd562f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=166941), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b93f4258c5247499f458798db70d857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9172), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27a07fef4fc45bc8df33d1e55050ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9172), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f291d18435dd4280b98c4312ab6a5021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7339), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab14cd9cda3446408d64bd17b0fb1a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7339), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "样本数量:\n",
      "\ttrain: 42,696\n",
      "\tval: 2,392\n",
      "\ttest: 1,885\n"
     ]
    }
   ],
   "source": [
    "datasets = {}\n",
    "\n",
    "for name, d in src_files.items():\n",
    "    samples = datasets[name] = []\n",
    "    with Pool() as pool, open(d['fp']) as fp:\n",
    "        total = d['lc']\n",
    "        mapper = pool.imap_unordered(\n",
    "            extract_samples,\n",
    "            tqdm(fp, total=total),\n",
    "            chunksize=min(1024, total//os.cpu_count()+1)\n",
    "        )\n",
    "        for data_list in tqdm(mapper, total=total):\n",
    "            samples.extend(data_list)\n",
    "\n",
    "print(f'样本数量:')\n",
    "for name, samples in datasets.items():\n",
    "    print(f'\\t{name}: {len(samples):,d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预览一条采样结果数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sep>我有轻微狐臭，手术后基本没有了。男友(一起两年，处俩月知我有腋臭)因此跟我分手，他说他能接受可他父母不能接受。我想知道大家对狐臭的看法，真的给另一半带来这么大负担吗？<sep><sep><|endoftext|>他能接受他父母不能接受，他是个孝子，姑娘，咱们成全他一辈子做孝子吧～～~我是毕业于宋仲基的故乡韩国思密达，愿以我的恰当对待，温暖陪伴，换取你敢于挣脱过去束缚的勇气。欢迎点我头像关注我，或私信我交流更多，也可直接预约我，我会主动联系您。\n"
     ]
    }
   ],
   "source": [
    "s = random.choice(datasets['test'])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 保存结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出目录: /home/Public/Megatron-LM/data/xinliqa-hunyin\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = os.path.abspath(\n",
    "    os.path.join(\n",
    "        'data',\n",
    "        'xinliqa-{0}'.format(slugify(TOPIC, separator='')),\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f'输出目录: {OUTPUT_DIR}')\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "乱序后直接保存所有输出样本到文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42eb4ce20d5043838c48d6117b15e2c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=42696, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c912a85a434acba6ea6fa4f80bc4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='val', max=2392, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b00ae1b8acf04bac9c0b4cd8b9738dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='test', max=1885, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for name, samples in datasets.items():\n",
    "    fname = os.path.join(OUTPUT_DIR, f'{name}.json')\n",
    "    with open(fname, 'w') as fp:\n",
    "        random.shuffle(samples)\n",
    "        for txt in tqdm(samples, name):\n",
    "            print(json.dumps({'text': txt}, ensure_ascii=False), file=fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查文件:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size:\n",
      "2.2M\t/home/Public/Megatron-LM/data/xinliqa-hunyin/test.json\n",
      "48M\t/home/Public/Megatron-LM/data/xinliqa-hunyin/train.json\n",
      "2.7M\t/home/Public/Megatron-LM/data/xinliqa-hunyin/val.json\n",
      "53M\t总用量\n",
      "\n",
      "line:\n",
      "    1885 /home/Public/Megatron-LM/data/xinliqa-hunyin/test.json\n",
      "   42696 /home/Public/Megatron-LM/data/xinliqa-hunyin/train.json\n",
      "    2392 /home/Public/Megatron-LM/data/xinliqa-hunyin/val.json\n",
      "   46973 总用量\n"
     ]
    }
   ],
   "source": [
    "!echo \"size:\"\n",
    "!du -hc {OUTPUT_DIR}/*.json\n",
    "\n",
    "!echo\n",
    "\n",
    "!echo \"line:\"\n",
    "!wc -l {OUTPUT_DIR}/*.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sep>不知道还要不要坚持 男朋友对我时好时坏的 有时候说的话很难听让我很想分手但是又说不出口让我很纠结 对我好的时候很好 对我不好的时候会打你狠话<sep><sep><|endoftext|>要在心理留有一个底线。不管他好的时候多好，坏的时候碰到了底线，你就该果断点。不然一辈子都只能在纠结中度过。\n"
     ]
    }
   ],
   "source": [
    "with fileinput.input(iglob(f'{OUTPUT_DIR}/*.json')) as fp:\n",
    "    for line in fp:\n",
    "        data = json.loads(line)\n",
    "        text = data['text']\n",
    "        print(text)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Megatron_LM-ipy]",
   "language": "python",
   "name": "conda-env-Megatron_LM-ipy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
