{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Megatron 直接使用预训练模型进行预测 (BPE v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 环境准备\n",
    "\n",
    "准备运行这个笔记本的 Jupyter kernel(**如果已经准备就绪，不要重复执行！**)：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 配置一个 Conda 环境作为 Jupyter Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %conda env update -f environments/environment-ipy.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "安装完毕后，为该 Notebook 选择这个 Kernel (名为`Megatron_LM-ipy`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 在Kernel所在 Conda 环境中安装 Apex\n",
    "\n",
    "需要通过 pip 从 github 下载源代码安装："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -v -r requirements/apex.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CD\n",
    "\n",
    "定位到工作目录，根据具体情况决定哦，不一定是下面的命令"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/Public/Megatron-LM\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 指定 Checkpoints 目录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从 S3 下载\n",
    "\n",
    "- 第一种选择：从 s3 下载\n",
    "\n",
    "文件比较大，根据实际情况选择下载，**不要重复下载**\n",
    "\n",
    "如果直接使用 S3 上的模型，需要下载，然后修改超参数, 路径等："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "\n",
    "HPARAMS_NAME = '117m'  # '345m'\n",
    "MODEL_NAME = '117m-hmwebmix_191128-bpe_v2' #  '345m-xinliqa-hunyin'\n",
    "TOKENIZER_TYPE = 'GPT2BPETokenizer_CN'\n",
    "\n",
    "AWSS3_CKPTS_DIR = os.path.join('s3://huamei/hmgpt2-checkpoints', MODEL_NAME)\n",
    "LOCAL_CKPTS_DIR = os.path.join('./checkpoints', MODEL_NAME)\n",
    "\n",
    "# 复制 latest_checkpointed_iteration.txt\n",
    "!aws s3 cp \\\n",
    "    {AWSS3_CKPTS_DIR} \\\n",
    "    {LOCAL_CKPTS_DIR} \\\n",
    "    --recursive \\\n",
    "    --exclude \"*\" \\\n",
    "    --include \"latest_checkpointed_iteration.txt\"\n",
    "\n",
    "# 下载后读取最新的 checkpoint iter 名称\n",
    "iteration = open(f'{LOCAL_CKPTS_DIR}/latest_checkpointed_iteration.txt').read()\n",
    "iteration = int(iteration)\n",
    "iteration_dir = 'iter_{:07d}'.format(iteration)\n",
    "\n",
    "awss3_ckpt_dir = os.path.join(AWSS3_CKPTS_DIR, iteration_dir)\n",
    "local_ckpt_dir = os.path.join(LOCAL_CKPTS_DIR, iteration_dir)\n",
    "\n",
    "print(f'{awss3_ckpt_dir} ==> {local_ckpt_dir}')\n",
    "    \n",
    "# 同步最新的 Checkpiont\n",
    "!aws s3 sync {awss3_ckpt_dir} {local_ckpt_dir}\n",
    "\n",
    "#\n",
    "load_model_dir = LOCAL_CKPTS_DIR\n",
    "print('load: ', load_model_dir)\n",
    "print('iteration: ', iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 直接使用本地\n",
    "\n",
    "- 另外一个选择：直接使用本地的已有模型\n",
    "\n",
    "修改超参数, 路径等："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load:  ./checkpoints/117m.spm-xinli_qa-hunyin\n",
      "iteration:  60000\n",
      "CPU times: user 2.47 ms, sys: 452 µs, total: 2.92 ms\n",
      "Wall time: 1.62 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "\n",
    "HPARAMS_NAME = '117m'\n",
    "TOKENIZER_TYPE = 'SentencePieceTokenizer'\n",
    "\n",
    "MODEL_NAME = '117m.spm-xinli_qa-hunyin'\n",
    "LOCAL_CKPTS_DIR = os.path.join('./checkpoints', MODEL_NAME)\n",
    "\n",
    "\n",
    "# 读取最新的 checkpoint iter 名称\n",
    "iteration = open(f'{LOCAL_CKPTS_DIR}/latest_checkpointed_iteration.txt').read()\n",
    "iteration_dir = 'iter_{:07d}'.format(int(iteration))\n",
    "\n",
    "local_ckpt_dir = os.path.join(LOCAL_CKPTS_DIR, iteration_dir)\n",
    "\n",
    "load_model_dir = LOCAL_CKPTS_DIR\n",
    "print('load: ', load_model_dir)\n",
    "print('iteration: ', iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 用哪个/些 GPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import csv\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from contextlib import closing\n",
    "from itertools import chain, compress\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "import mpu\n",
    "from data_utils.tokenization import SentencePieceTokenizer, make_tokenizer\n",
    "from pretrain_gpt2 import get_masks_and_position_ids\n",
    "from predict_gpt2 import initialize_distributed, prepare_tokenizer, set_random_seed, setup_model, get_token_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SimpleNamespace(\n",
    "    # Model arguments\n",
    "    # To be updated ...\n",
    "    vocab_size=None,\n",
    "    make_vocab_size_divisible_by=128,\n",
    "    attention_dropout=0.1,\n",
    "    hidden_dropout=0.1,\n",
    "    # Train/valid/test data arguments.\n",
    "    seq_length=1024,\n",
    "    model_parallel_size=1,\n",
    "    tokenizer_model_type='bert-large-uncased',\n",
    "    tokenizer_type=TOKENIZER_TYPE,\n",
    "    tokenizer_path=\"./data/spm/gpt2_huamei_corpus_bpe_32k_v2.model\",\n",
    "    cache_dir=None,\n",
    "    # Training arguments.\n",
    "    load=load_model_dir,\n",
    "    seed=1234,\n",
    "    checkpoint_activations=None,\n",
    "    checkpoint_num_layers=1,\n",
    "    finetune=None,\n",
    "    no_load_optim=None,\n",
    "    no_load_rng=None,\n",
    "    resume_dataloader=None,\n",
    "    fp16=True,\n",
    "    hysteresis=2,\n",
    "    loss_scale=None,\n",
    "    loss_scale_window=1000,\n",
    "    min_scale=1,\n",
    "    distributed_backend='nccl',\n",
    "    DDP_impl='local',\n",
    "    local_rank=None,\n",
    "    reset_position_ids=None,\n",
    "    reset_attention_mask=None,\n",
    "    eod_mask_loss=None, \n",
    "    # Text generate arguments.\n",
    "    recompute=None,\n",
    "    greedy=False,\n",
    "    top_p=0.0,\n",
    "    top_k=0,\n",
    "    temperature=1.0,\n",
    "    out_seq_length=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using world size: 1 and model-parallel size: 1 \n",
      " > using dynamic loss scaling\n"
     ]
    }
   ],
   "source": [
    "args.cuda = torch.cuda.is_available()\n",
    "args.rank = int(os.getenv('RANK', '0'))\n",
    "args.world_size = int(os.getenv(\"WORLD_SIZE\", '1'))\n",
    "\n",
    "if os.getenv('OMPI_COMM_WORLD_LOCAL_RANK'):\n",
    "    # We are using (OpenMPI) mpirun for launching distributed data parallel processes\n",
    "    local_rank = int(os.getenv('OMPI_COMM_WORLD_LOCAL_RANK'))\n",
    "    local_size = int(os.getenv('OMPI_COMM_WORLD_LOCAL_SIZE'))\n",
    "\n",
    "    # Possibly running with Slurm\n",
    "    num_nodes = int(os.getenv('SLURM_JOB_NUM_NODES', '1'))\n",
    "    nodeid = int(os.getenv('SLURM_NODEID', '0'))\n",
    "\n",
    "    args.local_rank = local_rank\n",
    "    args.rank = nodeid*local_size + local_rank\n",
    "    args.world_size = num_nodes*local_size\n",
    "\n",
    "args.model_parallel_size = min(args.model_parallel_size, args.world_size)\n",
    "if args.rank == 0:\n",
    "    print('using world size: {} and model-parallel size: {} '.format(\n",
    "        args.world_size, args.model_parallel_size))\n",
    "\n",
    "args.dynamic_loss_scale = False\n",
    "if args.loss_scale is None:\n",
    "    args.dynamic_loss_scale = True\n",
    "    if args.rank == 0:\n",
    "        print(' > using dynamic loss scaling')\n",
    "\n",
    "# The args fp32_* or fp16_* meant to be active when the\n",
    "# args fp16 is set. So the default behavior should all\n",
    "# be false.\n",
    "if not args.fp16:\n",
    "    args.fp32_embedding = False\n",
    "    args.fp32_tokentypes = False\n",
    "    args.fp32_layernorm = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "HPARAMS_SCHEMA = {\n",
    "    '117m': dict(\n",
    "        num_layers=12,\n",
    "        hidden_size=768,\n",
    "        num_attention_heads=12,\n",
    "        max_position_embeddings=1024,\n",
    "    ),\n",
    "    '345m': dict(\n",
    "        num_layers=24,\n",
    "        hidden_size=1024,\n",
    "        num_attention_heads=16,\n",
    "        max_position_embeddings=1024,\n",
    "    ),\n",
    "}\n",
    "\n",
    "# 设置 GPT-2 模型的超参数\n",
    "for k, v in HPARAMS_SCHEMA[HPARAMS_NAME].items():\n",
    "    setattr(args, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(DDP_impl='local', attention_dropout=0.1, cache_dir=None, checkpoint_activations=None, checkpoint_num_layers=1, cuda=True, distributed_backend='nccl', dynamic_loss_scale=True, eod_mask_loss=None, finetune=None, fp16=True, greedy=False, hidden_dropout=0.1, hidden_size=768, hysteresis=2, load='./checkpoints/117m.spm-xinli_qa-hunyin', local_rank=None, loss_scale=None, loss_scale_window=1000, make_vocab_size_divisible_by=128, max_position_embeddings=1024, min_scale=1, model_parallel_size=1, no_load_optim=None, no_load_rng=None, num_attention_heads=12, num_layers=12, out_seq_length=256, rank=0, recompute=None, reset_attention_mask=None, reset_position_ids=None, resume_dataloader=None, seed=1234, seq_length=1024, temperature=1.0, tokenizer_model_type='bert-large-uncased', tokenizer_path='./data/spm/gpt2_huamei_corpus_bpe_32k_v2.model', tokenizer_type='SentencePieceTokenizer', top_k=0, top_p=0.0, vocab_size=None, world_size=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化函数/全局变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = None\n",
    "model = None\n",
    "\n",
    "def initialize():\n",
    "    global model, tokenizer\n",
    "\n",
    "    # Disable CuDNN.\n",
    "    torch.backends.cudnn.enabled = False\n",
    "\n",
    "    # Pytorch distributed.\n",
    "    initialize_distributed(args)\n",
    "\n",
    "    # Random seeds for reproducability.\n",
    "    set_random_seed(args.seed)\n",
    "\n",
    "    # get the tokenizer\n",
    "    tokenizer = prepare_tokenizer(args)\n",
    "\n",
    "    # Model, optimizer, and learning rate.\n",
    "    model = setup_model(args)\n",
    "\n",
    "    args.device = torch.cuda.current_device()\n",
    "\n",
    "    # setting default batch size to 1\n",
    "    args.batch_size = 1\n",
    "\n",
    "    assert mpu.get_model_parallel_rank() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 主进程初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> initializing model parallel with size 1\n",
      "> initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234\n",
      "prepare tokenizer done\n",
      "building GPT2 model ...\n",
      " > number of parameters on model parallel rank 0: 110516736\n",
      "global rank 0 is loading checkpoint ./checkpoints/117m.spm-xinli_qa-hunyin/iter_0060000/mp_rank_00/model_optim_rng.pt\n",
      "  successfully loaded ./checkpoints/117m.spm-xinli_qa-hunyin/iter_0060000/mp_rank_00/model_optim_rng.pt\n",
      "CPU times: user 5.13 s, sys: 1.67 s, total: 6.8 s\n",
      "Wall time: 6.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore generating args\n",
    "def reset_generating_args(args):\n",
    "    args.recompute=False\n",
    "    args.top_p=0\n",
    "    args.top_k=0\n",
    "    args.temperature=1\n",
    "\n",
    "def infer_tokens_generative(context_tokens, model, tokenizer):\n",
    "    with torch.no_grad():\n",
    "        context_length = len(context_tokens)\n",
    "        token_stream = get_token_stream(model, [context_tokens], tokenizer, args)   \n",
    "        for i, (output_tokens, _) in enumerate(token_stream):\n",
    "            if context_length + i >= args.seq_length:\n",
    "                break\n",
    "            ids = output_tokens.cpu().numpy().tolist()[0]\n",
    "            yield ids[-1]\n",
    "\n",
    "\n",
    "def infer_text_generative(contex_text, model, tokenizer):\n",
    "    with torch.no_grad():\n",
    "        contex_text = contex_text.strip()\n",
    "        context_tokens = tokenizer.EncodeAsIds(contex_text).tokenization\n",
    "        context_length = len(context_tokens)\n",
    "\n",
    "        token_stream = get_token_stream(model, [context_tokens], tokenizer, args)\n",
    "\n",
    "        for i, (output_tokens, _) in enumerate(token_stream):\n",
    "            if context_length + i >= args.seq_length:\n",
    "                break\n",
    "            ids = output_tokens.cpu().numpy().tolist()[0]\n",
    "            s = tokenizer.DecodeIds([ids[-1]])\n",
    "            yield s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测试试看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = [\n",
    "    # 这几个是 train 数据\n",
    "#     (\n",
    "#         '老公说和女老师是闺蜜?觉得老公精神出轨该怎么办?',\n",
    "#         '与老公关系越来越冷漠。离婚是想过，但离婚结果是伤害三个人，最重的是孩子。我比较敏感，觉得老公精神出轨，或亦是十多年磨合也抹掉对我的在乎，我的一切理所当然归他，他没有危机感。就让为人在就好，其他交流没有都可以。他可以同学，同事（尤其是女同事）一呼百应，对我的情绪和需求却时而不见。我也不知道该不该离?离伤己，伤孩，更伤父母，我不想做做样子的罪人。但我与老公的交流无效，我活在一口枯井里，抑郁得不行，加上单位效益差，想过重读书或考技能证专业，短期又不现实，再八年就退休了。真心累，找不到出口。嫉妒心又强，就连儿子亲近爸爸，我都会嫉恨孩子的做法，（我从不查丈夫，孩子的手机，结果个个都设密码，我有时候找不到手机，想借用都打不开。）压抑这样子愤怒的情绪的非常累。怎么办?',\n",
    "#     ),\n",
    "#     (\n",
    "#         '前任和现在的纠结',\n",
    "#         '是这样的，我和前任分手了 原因是他真的太好了 我觉得我会耽搁了他 最后逼走了前任 现在我和现任在一起了 可是每隔一段时间我就在痛心和前任的事情 总是忍不住想找前任 有一次忍不住发了个信息给前任 结果间接导致了前任和他的女友分手了（当时我不知道他在拍拖） 现任对我很好 可是老是吵嘴 可是我老是在比较 觉得现任和前任的差别 就不自主的挂念着前任 后悔当初怎么选择逼走他 觉得对不住前任 可是我的第一次阴差阳错的给了现任了 触碰了这个底线 可是我又想和前任一起 现在好纠结 您觉得我是应该好好珍惜现任呢 还是重新争取前任 我知道我现在就是等于三心两意 好贱 可是自己又由不得自己似得 好讨厌这样的自己',\n",
    "#     ),\n",
    "\n",
    "    # 这几个是网上随便找的数据\n",
    "    (\n",
    "        '男人出轨',\n",
    "        '我的意思是，出轨者会问自己，我为什么要这么做，被背叛的伴侣会问，你为什么要这样对我?'\n",
    "    ),\n",
    "    (\n",
    "        '我的奇葩婚姻，老公说为了孩子好就是不离婚？',\n",
    "        '我的婚姻最近好像一塌糊涂，可是老公不离婚，我甚至有想过死？我是不是得了抑郁症？和老公从2017年开始就吵吵闹闹，一吵架就分居，分居一两个月老公可以对我和孩子不问不闻，到时间了他就自己又搬回来，但是回来也不和我沟通，就算是上次是他动手，他也不道歉，他特别喜欢冷战。现在和老公又发展到了无性，而且双方家庭也合不来，我和他家人不敢来往，他家人对我要求高，希望天天在家做饭带娃伺候老公，他现在和我父母也不来往，从来不回家吃饭，要等我父母走了他才回来，每天很晚回家，去哪从来不告诉我，我知道他有婚外性，但他從來不承認，还说我是神经病，我還被他傳播上了高危型的HPV，以后是死是活都不确定，我特别想要离婚，我感觉和他生活快要窒息了，他整天拉着个脸，要么对我不闻不问，要么一开口说话就是责怪的语气，但他就是不离婚，说是为了孩子好，还让我不要发神经，我真的不知道该怎么和他相处了。他性格很古怪'\n",
    "    ),\n",
    "    (\n",
    "        '妻子在钱的问题上不坦诚，如何处理好家庭经济问题？',\n",
    "        '和老婆因为意外怀孕结婚，两家谈婚论嫁时闹得不愉快，我家出了一套大户型的房子，一台豪华车（当然这些都是婚前财产），然后给了40万装修婚房，同时给女方10万彩礼。而女方一开始的态度是一分钱没有，后来迫于压力给了50万现金，我老婆名下既没有房也没有车。婚后的钱一直都是给我老婆管理，包括我的工资奖金还有结婚的份子钱等等。我老婆并没有把这些钱看做是家庭财产，就算其中已经掺入了很多我的钱，还是认为全部都是她自己的钱，我只是知道她的卡密码而已，但是卡在哪里，她花了多少钱，花在哪里了，有没有借钱给别人，我通通不知道，这让我很不安。况且她没有理财观念，我曾经三番五次跟她说了理财的重要性，她就只是沉默不语，也不知道是听不懂，还是装傻实际上自己去做了理财但是没把收入情况告诉我，我们多次吵架都是为了钱，我觉得夫妻两个在这个问题上不能坦诚是个大问题，我现在很想经济分开，但是不知道怎么做才比较妥当'\n",
    "    ),\n",
    "    (\n",
    "        '30岁男生，相亲屡次不顺，我该怎么办呢？',\n",
    "        '30岁男生还单身，相亲对象不少，可是次次都以失败收场，自己长相还行，就是不太会说话，和女生聊天刚开始聊的挺不错，没聊几天女的就不回复了，爱答不理，心里郁闷的晚上都想哭，我该怎么办'\n",
    "    ),\n",
    "    (\n",
    "        '30岁女生，离婚念头挥之不去，他为何计划婚内出轨？',\n",
    "        '此刻有点儿失眠心情烦躁，我想了很久没有想明白，为什么他会计划着婚内出轨，……心里，我基本上认定原因应该是我身材不怎么好，胸部不够吸引人，因为婚后发现了在婚前，他约P了一个又肥又长相不佳的女人。我以为就是因为对方胸部傲人。在壹心理一些文章的引导下，我突然明白，源头是性生活不和谐。婚前同居一年多，到婚后2年，性生活基本就是，直奔主题，他一手拿着手机欣赏着他的成人影片一边爱爱，很少会主动关心我的感受，也很少理会我让他收起手机的要求。而且另一方面，他基本每晚都会要求我用嘴亲亲，他自己则拿着手机看片或者无关紧要的东西，让我经常觉得自己就是一个娃娃一个工具。以前我主动跟他说起过几次，然而也只是不了了之。后来我基本对性生活没有兴趣，也很反感为他口J。而且，日常生活变得频繁小吵冷战，很少有之前无话不谈的亲密，我不知道我们还有没有重归于好的机会……'\n",
    "    ),\n",
    "    (\n",
    "        '29岁哺乳期，和公婆因带孩子问题每天崩溃，怎么办？',\n",
    "        '怀孕她就没怎么管，备产各种东西都是自己准备。产后直接是妈妈照顾的。产后半年回来要上班，我爸妈又没退休，无奈下还是他们来照顾。他们方法不对，连个衣服都洗不干净，更不用提孩子的饭了。每天我都自己趁下班时间给孩子准备饭和各种东西。最怕的是习惯，比如她喜欢喂孩子各种炒菜，我说好几次一岁之内吃盐不好就是不听，还故意喂。或者孩子的奶瓶，经常不盖盖子让他把玩，说不卫生，也不搭理。孩子吃饭的碗和勺子永远是扔在各种桌子椅子角落，用的时候直接拿起来用也不洗，洗脸洗脚水每次告诉温度差不多就好了，就是不听，偏要一会冷一会烫。来我家被子也不叠，锅永远是不会洗的，下一顿加水加米接着煮。我老公又每天忙的不在家，我已经要崩溃了'\n",
    "    ),\n",
    "    (\n",
    "        '婚后分居三四年，有过家庭矛盾，我的婚姻是否该继续？',\n",
    "        '婚后分居三四年，和老公之间发生过一些家庭矛盾，可以看我另外一篇疑问。我们上半年闹离婚，后来他又主动和好，但是我们之前除了新婚，几乎很少有夫妻生活，他说一靠近我就觉得心里像一堆蚂蚁抓挠，特别难受。他说这是他得心理问题，小时候受到唾骂和凌辱，造成了心理阴影。我们俩都觉得生活的很痛苦，但为了孩子没有离婚。我跟他在一起就觉得拘束，不自在。向往的温馨家庭生活也得不到，我很累，我应该坚持离婚吗？他这种心理疾病是真的还是借口呢？'\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "男人出轨\n",
      "\n",
      "我的意思是，出轨者会问自己，我为什么要这么做，被背叛的伴侣会问，你为什么要这样对我?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "1:\t<|endoftext|>离婚也许是一种一个取舍感,挫败感,对亲密感,以及你的吸引力。第三,自己的生活要自己承担责任就有。女人都是重感情的,建议你给这个男人客观的建议,就是你自己的感受,而不是去应对外人给予的。我想你可以再深入的沟通一下,说不定什么时候成为你和他之间的性格特点,以及你如何改变都会是你接受的底线。 <eos>\n",
      "\n",
      "2:\t<|endoftext|>关系封闭了我们很容易存续的阴影,感觉危险并没有怎么样。很容易互相我看到他的隐私,因为什么不这个事件还是想看看。 <eos>\n",
      "\n",
      "3:\t<|endoftext|>你得先杂志和夫妻之间学会如何化解紧张,把自己思维处理好了,越来越晴上天建议你去做一些独立的呼吸对,然后再争吵,引起意外的爱。每个人都是需要爱的,不需要经历肌肤之亲。也可以去回忆你们如何下去的?他出轨如何,而且婚姻从来都不是一个人的事情,需要双方都认可的伴侣。 <eos>\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "我的奇葩婚姻，老公说为了孩子好就是不离婚？\n",
      "\n",
      "我的婚姻最近好像一塌糊涂，可是老公不离婚，我甚至有想过死？我是不是得了抑郁症？和老公从2017年开始就吵吵闹闹，一吵架就分居，分居一两个月老公可以对我和孩子不问不闻，到时间了他就自己又搬回来，但是回来也不和我沟通，就算是上次是他动手，他也不道歉，他特别喜欢冷战。现在和老公又发展到了无性，而且双方家庭也合不来，我和他家人不敢来往，他家人对我要求高，希望天天在家做饭带娃伺候老公，他现在和我父母也不来往，从来不回家吃饭，要等我父母走了他才回来，每天很晚回家，去哪从来不告诉我，我知道他有婚外性，但他從來不承認，还说我是神经病，我還被他傳播上了高危型的HPV，以后是死是活都不确定，我特别想要离婚，我感觉和他生活快要窒息了，他整天拉着个脸，要么对我不闻不问，要么一开口说话就是责怪的语气，但他就是不离婚，说是为了孩子好，还让我不要发神经，我真的不知道该怎么和他相处了。他性格很古怪\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "1:\t<|endoftext|>他比较内向,对孩子也不够关心,你们俩个孩子,把孩子给他妈妈也是犯了错误,以后你们俩就算没离婚,你们俩还是能和平解决的。你才22岁,应该还年轻,以后有了孩子,矛盾肯定会更多,不管你们谁对孩子怎么样,都要让孩子去解决父母之间的关系。 <eos>\n",
      "\n",
      "2:\t<|endoftext|>两个人的关系出现问题,是每一个人都有其独特性。要想和他和平相处,就需要从更多的人际关系着手,在共同生活方面多多交流,如果实在做不到,那就找咨询师协助吧! <eos>\n",
      "\n",
      "3:\t<|endoftext|>1、“对他不满”引发你的怒火?2、“他是个经常挑剔你,还是不爱你的这种性格呢?2,男生之间,本该是对你有较高的要求和控制自己的情绪”的,这个需要好好思考的。虽然后来他无意,但是一言难尽..该不该结婚不该不是你决定的关键。很多女孩都有一个优缺点,如果想要结婚,再过个十年都个十年,再过十年都不是的男人了,如果对方是什么缺点你想要的优点是永恒不变的,那可为什么呢?6.当婚姻中遇到问题,不能解决,而找对方的伴侣,是否能接受,要么努力去互相解决,要么坦然接受。 <eos>\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "妻子在钱的问题上不坦诚，如何处理好家庭经济问题？\n",
      "\n",
      "和老婆因为意外怀孕结婚，两家谈婚论嫁时闹得不愉快，我家出了一套大户型的房子，一台豪华车（当然这些都是婚前财产），然后给了40万装修婚房，同时给女方10万彩礼。而女方一开始的态度是一分钱没有，后来迫于压力给了50万现金，我老婆名下既没有房也没有车。婚后的钱一直都是给我老婆管理，包括我的工资奖金还有结婚的份子钱等等。我老婆并没有把这些钱看做是家庭财产，就算其中已经掺入了很多我的钱，还是认为全部都是她自己的钱，我只是知道她的卡密码而已，但是卡在哪里，她花了多少钱，花在哪里了，有没有借钱给别人，我通通不知道，这让我很不安。况且她没有理财观念，我曾经三番五次跟她说了理财的重要性，她就只是沉默不语，也不知道是听不懂，还是装傻实际上自己去做了理财但是没把收入情况告诉我，我们多次吵架都是为了钱，我觉得夫妻两个在这个问题上不能坦诚是个大问题，我现在很想经济分开，但是不知道怎么做才比较妥当\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "1:\t<|endoftext|>我感觉您希望经济分开的背后是委屈和恐惧。从叙述来看结婚最大的花销房子和车都是您这边出的,女方出的50万是“迫于压力”再加上婚后对这些财产没什么话语权,难免有种被剥削的感觉。婚后您愿意把钱给老婆管从某种程度说明了您对她的爱和信任,况且大头依然属于您的婚前财产。所以,也许您更需要她态度上的反馈,这种反馈应该和您的爱与信任相匹配。看一看有没有哪一次妻子愿意跟您讨论家里钱的问题,当时双方是如何沟通的,再把您可以接受的经济管理方式提出来,比如怎么做可以让您有安全感。当然最后实在想拿在自己手里,我相信您自己肯定有办法。 <eos>\n",
      "\n",
      "2:\t<|endoftext|>我感觉您希望经济分开的背后是委屈和恐惧。从叙述来看结婚最大的花销房子和车都是您这边出的,女方出的50万是“迫于压力”再加上婚后对这些财产没什么话语权,难免有种被剥削的感觉。婚后您愿意把钱给老婆管从某种程度说明了您对她的爱和信任,况且大头依然属于您的婚前财产。所以,也许您更需要她态度上的反馈,这种反馈应该和您的爱与信任相匹配。看一看有没有哪一次妻子愿意跟您讨论家里钱的问题,当时双方是如何沟通的,再把您可以接受的经济管理方式提出来,比如怎么做可以让您有安全感。当然最后实在想拿在自己手里,我相信您自己肯定有办法。 <eos>\n",
      "\n",
      "3:\t<|endoftext|>你把你的钱财都交给了她,但是你不知道该给什么。她会给你的经济压力,但是不会摧毁你们的感情。就像上班时间不长,可以慢慢让妻子自己开支耗费,让你可以尝试一点点还钱。当然,如果这个妻子没有得到的,或者意义就需要你多给她一些。当她感觉到你对他的爱了,她就会变得收敛了。这只是一个导火索,那就是在婚姻里,需要用智慧去应对这样的风险。 <eos>\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "30岁男生，相亲屡次不顺，我该怎么办呢？\n",
      "\n",
      "30岁男生还单身，相亲对象不少，可是次次都以失败收场，自己长相还行，就是不太会说话，和女生聊天刚开始聊的挺不错，没聊几天女的就不回复了，爱答不理，心里郁闷的晚上都想哭，我该怎么办\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "1:\t<|endoftext|>楼主你好,我是爱A,我想这个是不是“会的,喜欢爱情,喜欢啊”,这样的关系我真的可以感觉到,长时间恋爱后也会变了,不是想要什么解决的问题,问题在于你对自己不自信,也不自信,旺而相爱是很正常的现象,不要因为这些事情就不再发生的多了嘛。)A批评你,也别猜着敏感的心痛,当你有了孩子他还是会对你很好,不用担心他还那就好好经营好自己的大部分人吧,幸福健康的感情总比金钱重要。 <eos>\n",
      "\n",
      "2:\t<|endoftext|>你喜欢一个大男孩吗?如果还喜欢,那真的有心吸引力吗?勇敢去追求吧,不要在意结果,不然以后会后悔。 <eos>\n",
      "\n",
      "3:\t<|endoftext|>你真的喜欢轰烈烈、解放性格吗?最近两个月,挺能确认他喜不喜欢你这些外在的东西。如果间感情到了稳固感情就没有基础,是不是有点抵触如果要主动的话,建议最好去试一试,看看最后会怎么样。 <eos>\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "30岁女生，离婚念头挥之不去，他为何计划婚内出轨？\n",
      "\n",
      "此刻有点儿失眠心情烦躁，我想了很久没有想明白，为什么他会计划着婚内出轨，……心里，我基本上认定原因应该是我身材不怎么好，胸部不够吸引人，因为婚后发现了在婚前，他约P了一个又肥又长相不佳的女人。我以为就是因为对方胸部傲人。在壹心理一些文章的引导下，我突然明白，源头是性生活不和谐。婚前同居一年多，到婚后2年，性生活基本就是，直奔主题，他一手拿着手机欣赏着他的成人影片一边爱爱，很少会主动关心我的感受，也很少理会我让他收起手机的要求。而且另一方面，他基本每晚都会要求我用嘴亲亲，他自己则拿着手机看片或者无关紧要的东西，让我经常觉得自己就是一个娃娃一个工具。以前我主动跟他说起过几次，然而也只是不了了之。后来我基本对性生活没有兴趣，也很反感为他口J。而且，日常生活变得频繁小吵冷战，很少有之前无话不谈的亲密，我不知道我们还有没有重归于好的机会……\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "1:\t<|endoftext|>你老公对你还不错,但是由于种种原因,他两次忽视你的精神需求,对性生活的不满意,对性生活的排斥,对性生活的排斥,性生活的不满足,性生活质量是不可避免的,所以性生活也是促进情感生活的剂品性,尽量避免强迫性生活持续时间,尽量避免对性生活带来影响,性生活质量,尽量避免对性生活影响,性生活质量,性生活平均平均平均3次性降低,如果性生活质量还好,那可以考虑离婚,如果当下生活还是可以,就婚姻中多看看多些性知识,降低关注生活和个人性知识,如果还是无法满足,就需要夫妻双方都满足,如果一方寻求满足,那婚姻就可能满足生儿戏了。 <eos>\n",
      "\n",
      "2:\t<|endoftext|>你好,对于性生活,你的问题很清晰,就是很在意老公是否出轨,就事论事,你老公很在意你是否在意。对于性,对于性生活,对于他的的话题,任何解释,都没有对你的了解。你老公在平日里是否表现的特别关心你,甚至更在意的是否定了你对他的关心。这不仅仅是性生活,还有性生活。 <eos>\n",
      "\n",
      "3:\t<|endoftext|>梦想是什么?有几种理论你可以思考以上...人的欲望是根据个人内心的想法。想要判断是否正确的,与他人沟通,获取别人的理解与支持很重要。 <eos>\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "29岁哺乳期，和公婆因带孩子问题每天崩溃，怎么办？\n",
      "\n",
      "怀孕她就没怎么管，备产各种东西都是自己准备。产后直接是妈妈照顾的。产后半年回来要上班，我爸妈又没退休，无奈下还是他们来照顾。他们方法不对，连个衣服都洗不干净，更不用提孩子的饭了。每天我都自己趁下班时间给孩子准备饭和各种东西。最怕的是习惯，比如她喜欢喂孩子各种炒菜，我说好几次一岁之内吃盐不好就是不听，还故意喂。或者孩子的奶瓶，经常不盖盖子让他把玩，说不卫生，也不搭理。孩子吃饭的碗和勺子永远是扔在各种桌子椅子角落，用的时候直接拿起来用也不洗，洗脸洗脚水每次告诉温度差不多就好了，就是不听，偏要一会冷一会烫。来我家被子也不叠，锅永远是不会洗的，下一顿加水加米接着煮。我老公又每天忙的不在家，我已经要崩溃了\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "1:\t<|endoftext|>看完了你的叙述,你和你老公的婚姻并不太理想,甚至不能怀孕。但是你有没有想过,怀孕之后心情怎么样?有没有和你的老公聊过?他的想法是什么?如果他一直这样,你能接受吗?他会改变吗?你觉得这样的婚姻状态好像很困难,如果没有改变,是否会成为怀孕的对象?如果改变,风险不太大的话可以考虑:如果一个人找不到工作,那么在职场的话,也许可以做些让自己放松的事,缓解一下这段时间的焦虑。 <eos>\n",
      "\n",
      "2:\t<|endoftext|>你好,我是心理机构咨询师刘老师。希望以下回答能帮助到你:1、从你描述来看,你认为老公对你的忽视是指责抱怨,还是指责的?2、似乎你的表达中,你希望他能多和你讲话,照顾自己的孩子和承担起家庭的责任,但并指向小孩,自己要承担起家庭责任,是这样吗?2、老公的妈妈应该也是一个被溺爱的小女孩,他要承担的责任,家里两个孩子,那他不仅要担负起家庭责任,还要担负起自己的责任,变成一个“自私”的男人,对家庭的责任更不能有自己的责任,没有义务为这个家而焦虑,本身就爆发的更大的脾气,这件事可能成为你希望的结果。要想清楚,你首先需要明白,家庭的责任,夫妻之间,共同努力达成共识,不能同甘共苦,得过且过下去。 <eos>\n",
      "\n",
      "3:\t<|endoftext|>看完了你的叙述,你对你爸妈还不错,家里很多东西什么都包了但并没有换位思考,就是你爸妈来帮忙照顾,想给你买鞋礼物,从满足了你现在的状况吧。没有其他优点。这个时候边先找老公,让你老公体会到你的好感,你也多对他父母满意的表现。尽量多跟他沟通,把你想要的满意放在桌子上跟他商量一下,尽量不要让他觉得到你照顾你,自己帮你爸妈说这件事不要超过一年搞大的事,也不用太在乎你老公的事,一下就问你的意见,让人莫名其妙。我是要他照顾到有先,在家的时候挺伤心的。照顾孩子,是你们的最好解决,他爸妈待你不出去住一段时间,会好点。毕竟你们现在只是偶尔的相处,就像你说的,他在家没有责任感,也有些不喜欢和你商量。认真的想想,我是因为这个他老婆的工作,他觉得他觉得你不会理所应当,会得一点点的用。好像你老公也想当你是对的,所以他才想和你达成某种要求。其实你和你老公矛盾很正常,事实证明他根本没有意识到这个问题。只是他妹妹毕竟是两个人的事情,你们两个都是一家人了,想要构建起你们两个家庭。辞\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "婚后分居三四年，有过家庭矛盾，我的婚姻是否该继续？\n",
      "\n",
      "婚后分居三四年，和老公之间发生过一些家庭矛盾，可以看我另外一篇疑问。我们上半年闹离婚，后来他又主动和好，但是我们之前除了新婚，几乎很少有夫妻生活，他说一靠近我就觉得心里像一堆蚂蚁抓挠，特别难受。他说这是他得心理问题，小时候受到唾骂和凌辱，造成了心理阴影。我们俩都觉得生活的很痛苦，但为了孩子没有离婚。我跟他在一起就觉得拘束，不自在。向往的温馨家庭生活也得不到，我很累，我应该坚持离婚吗？他这种心理疾病是真的还是借口呢？\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "1:\t<|endoftext|>24岁单身萌生子的男人反而会让你难受特别在意这些情绪上的话会让你的内心更踏实一些,男人并不一定就是坏事有一个结果,当我们爱上一个人的时候,我们就会在心里面有一些失衡。不妨我们来想一想,生活里我们渴望和什么样的男人?再者,也许是你想要的,那么你就会知道,也许并不那么了解。从而实现自己的内心需求,才能向内求,去做出取舍。 <eos>\n",
      "\n",
      "2:\t<|endoftext|>你不想离婚,那么他似乎也不太想离婚,但是为何你会这样去选择呢?是什么让你决定和他离婚呢?这些原因,都是需要探索的,如果你愿意可以和我联系。 <eos>\n",
      "\n",
      "3:\t<|endoftext|>你好,能够理解你的心情。你老公的性格是互补型的,并且是喜欢着你的,但是你老公身上一定有你的道理,对不对?不知道你们结婚多长时间了?你和老公的性格特点是怎样的?你理想的生活是怎样的?你能选择来这里求助,就非常的不简单。咨询是一个过程,我需要了解更多的情况,才能帮你分析解决问题。我帮助过很多和你一样困扰的人,相信也可以帮到你。可以多说一些你的情况吗? <eos>\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_gen = 3\n",
    "\n",
    "reset_generating_args(args)\n",
    "try:\n",
    "#     args.recompute = True\n",
    "    for title, text in input_texts:\n",
    "        context_string = f'{title}<sep>{text}<sep><sep>'\n",
    "#         context_string += '<|endoftext|>'\n",
    "        print(title)\n",
    "        print()\n",
    "        print(text)\n",
    "        print('-' * 100)\n",
    "        print()\n",
    "        for i in range(n_gen):\n",
    "            args.top_p=random.gauss(0.5, 0.5)\n",
    "            args.temperature=random.gauss(1, 0.05)\n",
    "            print(f'{i+1}:\\t', end='')\n",
    "            context_tokens = tokenizer.EncodeAsIds(context_string).tokenization\n",
    "            for id_ in infer_tokens_generative(context_tokens, model, tokenizer):\n",
    "                s = tokenizer.DecodeIds([id_])\n",
    "                print(s, end='')\n",
    "            print(os.linesep)\n",
    "        print()\n",
    "        print('=' * 100)\n",
    "        print()\n",
    "finally:\n",
    "    reset_generating_args(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 test 语料，从中随机打断，并预测下文，比较原文与预测结果！\n",
    "\n",
    "随机选 N 个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_file=./data/xinliqa-hunyin/test.infer-345m.iter_0050000-200x256x5-shuffle_False-191125120008.tsv\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "ts = datetime.now().strftime('%y%m%d%H%M%S')\n",
    "\n",
    "\n",
    "N = 200\n",
    "SHUFFLING = False\n",
    "INFER_COUNT = 5\n",
    "\n",
    "input_file = './data/xinliqa-hunyin/test.json'\n",
    "output_file = f'./data/xinliqa-hunyin/test.infer-{HPARAMS_NAME}.{iteration_dir}-{N}x{args.out_seq_length}x{INFER_COUNT}-shuffle_{SHUFFLING}-{ts}.tsv'\n",
    "\n",
    "print(f'output_file={output_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c10fdf19924ecbac78cf2cde3311e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test 数据总数: 1,885\n",
      "Test 采样数: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0381dfc8cbae433096b4e14cfddf01c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='sample', max=200, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5859d72354d4f4c971b7254ef73cd32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='generate', max=200, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total = sum(1 for _ in tqdm(open(input_file)))\n",
    "print(f'Test 数据总数: {total:,d}')\n",
    "\n",
    "assert total >= N\n",
    "\n",
    "print(f'Test 采样数: {N:,d}')\n",
    "\n",
    "mask = np.zeros(total, dtype=int)\n",
    "mask[:N] = 1\n",
    "if SHUFFLING:\n",
    "    np.random.shuffle(mask)\n",
    "\n",
    "samples = []\n",
    "with open(input_file) as fp:\n",
    "    reader = compress(fp, mask)\n",
    "    for line in tqdm(reader, 'sample', total=N):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        text = json.loads(line)['text']\n",
    "        question, answer = text.strip().split('<|endoftext|>')\n",
    "        question_title, question_text = question.split('<sep>')[:2]\n",
    "        samples.append([question_title, question_text, answer])\n",
    "if SHUFFLING:\n",
    "    random.shuffle(samples)\n",
    "\n",
    "with open(output_file, 'w') as fp:\n",
    "    writer = csv.writer(fp, delimiter='\\t')\n",
    "    for question_title, question_text, answer in tqdm(samples, 'generate'):\n",
    "        row = [question_title, question_text, answer]\n",
    "        txt = f'{question_title}<sep>{question_text}<sep><sep><|endoftext|>'\n",
    "        for _ in range(INFER_COUNT):\n",
    "            reset_generating_args(args)\n",
    "            try:\n",
    "                args.recompute=True\n",
    "                args.top_p=random.gauss(0.5, 0.5)\n",
    "                args.temperature=random.gauss(1, 0.05)\n",
    "                infer_txt = ''.join(infer_text_generative(txt, model, tokenizer))\n",
    "                row.append(infer_txt)                \n",
    "            finally:\n",
    "                reset_generating_args(args)\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Megatron_LM-ipy]",
   "language": "python",
   "name": "conda-env-Megatron_LM-ipy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
