{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Megatron 直接使用预训练模型进行预测 (BPE v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 环境准备\n",
    "\n",
    "准备运行这个笔记本的 Jupyter kernel(**如果已经准备就绪，不要重复执行！**)：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 配置一个 Conda 环境作为 Jupyter Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %conda env update -f environments/environment-ipy.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "安装完毕后，为该 Notebook 选择这个 Kernel (名为`Megatron_LM-ipy`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 在Kernel所在 Conda 环境中安装 Apex\n",
    "\n",
    "需要通过 pip 从 github 下载源代码安装："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -v -r requirements/apex.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CD\n",
    "\n",
    "定位到工作目录，根据具体情况决定哦，不一定是下面的命令"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/Public/Megatron-LM\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 指定 Checkpoints 目录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从 S3 下载\n",
    "\n",
    "- 第一种选择：从 s3 下载\n",
    "\n",
    "文件比较大，根据实际情况选择下载，**不要重复下载**\n",
    "\n",
    "如果直接使用 S3 上的模型，需要下载，然后修改超参数, 路径等："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://huamei/hmgpt2-checkpoints/117m-hmwebmix_191128-bpe_v2/latest_checkpointed_iteration.txt to checkpoints/117m-hmwebmix_191128-bpe_v2/latest_checkpointed_iteration.txt\n",
      "s3://huamei/hmgpt2-checkpoints/117m-hmwebmix_191128-bpe_v2/iter_0015000 ==> ./checkpoints/117m-hmwebmix_191128-bpe_v2/iter_0015000\n",
      "download: s3://huamei/hmgpt2-checkpoints/117m-hmwebmix_191128-bpe_v2/iter_0015000/mp_rank_00/model_optim_rng.pt to checkpoints/117m-hmwebmix_191128-bpe_v2/iter_0015000/mp_rank_00/model_optim_rng.pt\n",
      "load:  ./checkpoints/117m-hmwebmix_191128-bpe_v2\n",
      "iteration:  15000\n",
      "CPU times: user 8.27 s, sys: 2.16 s, total: 10.4 s\n",
      "Wall time: 3min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "\n",
    "HPARAMS_NAME = '117m'  # '345m'\n",
    "MODEL_NAME = '117m-hmwebmix_191128-bpe_v2' #  '345m-xinliqa-hunyin'\n",
    "TOKENIZER_TYPE = 'GPT2BPETokenizer_CN'\n",
    "\n",
    "AWSS3_CKPTS_DIR = os.path.join('s3://huamei/hmgpt2-checkpoints', MODEL_NAME)\n",
    "LOCAL_CKPTS_DIR = os.path.join('./checkpoints', MODEL_NAME)\n",
    "\n",
    "# 复制 latest_checkpointed_iteration.txt\n",
    "!aws s3 cp \\\n",
    "    {AWSS3_CKPTS_DIR} \\\n",
    "    {LOCAL_CKPTS_DIR} \\\n",
    "    --recursive \\\n",
    "    --exclude \"*\" \\\n",
    "    --include \"latest_checkpointed_iteration.txt\"\n",
    "\n",
    "# 下载后读取最新的 checkpoint iter 名称\n",
    "iteration = open(f'{LOCAL_CKPTS_DIR}/latest_checkpointed_iteration.txt').read()\n",
    "iteration = int(iteration)\n",
    "iteration_dir = 'iter_{:07d}'.format(iteration)\n",
    "\n",
    "awss3_ckpt_dir = os.path.join(AWSS3_CKPTS_DIR, iteration_dir)\n",
    "local_ckpt_dir = os.path.join(LOCAL_CKPTS_DIR, iteration_dir)\n",
    "\n",
    "print(f'{awss3_ckpt_dir} ==> {local_ckpt_dir}')\n",
    "    \n",
    "# 同步最新的 Checkpiont\n",
    "!aws s3 sync {awss3_ckpt_dir} {local_ckpt_dir}\n",
    "\n",
    "#\n",
    "load_model_dir = LOCAL_CKPTS_DIR\n",
    "print('load: ', load_model_dir)\n",
    "print('iteration: ', iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 直接使用本地\n",
    "\n",
    "- 另外一个选择：直接使用本地的已有模型\n",
    "\n",
    "修改超参数, 路径等："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load:  ./checkpoints/117m.spm-xinli_qa-hunyin\n",
      "iteration:  60000\n",
      "CPU times: user 628 µs, sys: 140 µs, total: 768 µs\n",
      "Wall time: 476 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "\n",
    "HPARAMS_NAME = '117m'\n",
    "TOKENIZER_TYPE = 'SentencePieceTokenizer'\n",
    "\n",
    "MODEL_NAME = '117m.spm-xinli_qa-hunyin'\n",
    "AWSS3_CKPTS_DIR = os.path.join('s3://huamei/hmgpt2-checkpoints', MODEL_NAME)\n",
    "LOCAL_CKPTS_DIR = os.path.join('./checkpoints', MODEL_NAME)\n",
    "\n",
    "\n",
    "# 读取最新的 checkpoint iter 名称\n",
    "iteration = open(f'{LOCAL_CKPTS_DIR}/latest_checkpointed_iteration.txt').read()\n",
    "iteration_dir = 'iter_{:07d}'.format(int(iteration))\n",
    "\n",
    "local_ckpt_dir = os.path.join(LOCAL_CKPTS_DIR, iteration_dir)\n",
    "\n",
    "load_model_dir = LOCAL_CKPTS_DIR\n",
    "print('load: ', load_model_dir)\n",
    "print('iteration: ', iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 用哪个/些 GPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import csv\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from contextlib import closing\n",
    "from itertools import chain, compress\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "import mpu\n",
    "from data_utils.tokenization import SentencePieceTokenizer, make_tokenizer\n",
    "from pretrain_gpt2 import get_masks_and_position_ids\n",
    "from predict_gpt2 import initialize_distributed, prepare_tokenizer, set_random_seed, setup_model, get_token_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SimpleNamespace(\n",
    "    # Model arguments\n",
    "    # To be updated ...\n",
    "    vocab_size=None,\n",
    "    make_vocab_size_divisible_by=128,\n",
    "    attention_dropout=0.1,\n",
    "    hidden_dropout=0.1,\n",
    "    # Train/valid/test data arguments.\n",
    "    seq_length=1024,\n",
    "    model_parallel_size=1,\n",
    "    tokenizer_model_type='bert-large-uncased',\n",
    "    tokenizer_type=TOKENIZER_TYPE,\n",
    "    tokenizer_path=\"./data/spm/gpt2_huamei_corpus_bpe_32k_v2.model\",\n",
    "    cache_dir=None,\n",
    "    # Training arguments.\n",
    "    load=load_model_dir,\n",
    "    seed=1234,\n",
    "    checkpoint_activations=None,\n",
    "    checkpoint_num_layers=1,\n",
    "    finetune=None,\n",
    "    no_load_optim=None,\n",
    "    no_load_rng=None,\n",
    "    resume_dataloader=None,\n",
    "    fp16=True,\n",
    "    hysteresis=2,\n",
    "    loss_scale=None,\n",
    "    loss_scale_window=1000,\n",
    "    min_scale=1,\n",
    "    distributed_backend='nccl',\n",
    "    DDP_impl='local',\n",
    "    local_rank=None,\n",
    "    reset_position_ids=None,\n",
    "    reset_attention_mask=None,\n",
    "    eod_mask_loss=None, \n",
    "    # Text generate arguments.\n",
    "    recompute=None,\n",
    "    greedy=False,\n",
    "    top_p=0.0,\n",
    "    top_k=0,\n",
    "    temperature=1.0,\n",
    "    out_seq_length=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using world size: 1 and model-parallel size: 1 \n",
      " > using dynamic loss scaling\n"
     ]
    }
   ],
   "source": [
    "args.cuda = torch.cuda.is_available()\n",
    "args.rank = int(os.getenv('RANK', '0'))\n",
    "args.world_size = int(os.getenv(\"WORLD_SIZE\", '1'))\n",
    "\n",
    "if os.getenv('OMPI_COMM_WORLD_LOCAL_RANK'):\n",
    "    # We are using (OpenMPI) mpirun for launching distributed data parallel processes\n",
    "    local_rank = int(os.getenv('OMPI_COMM_WORLD_LOCAL_RANK'))\n",
    "    local_size = int(os.getenv('OMPI_COMM_WORLD_LOCAL_SIZE'))\n",
    "\n",
    "    # Possibly running with Slurm\n",
    "    num_nodes = int(os.getenv('SLURM_JOB_NUM_NODES', '1'))\n",
    "    nodeid = int(os.getenv('SLURM_NODEID', '0'))\n",
    "\n",
    "    args.local_rank = local_rank\n",
    "    args.rank = nodeid*local_size + local_rank\n",
    "    args.world_size = num_nodes*local_size\n",
    "\n",
    "args.model_parallel_size = min(args.model_parallel_size, args.world_size)\n",
    "if args.rank == 0:\n",
    "    print('using world size: {} and model-parallel size: {} '.format(\n",
    "        args.world_size, args.model_parallel_size))\n",
    "\n",
    "args.dynamic_loss_scale = False\n",
    "if args.loss_scale is None:\n",
    "    args.dynamic_loss_scale = True\n",
    "    if args.rank == 0:\n",
    "        print(' > using dynamic loss scaling')\n",
    "\n",
    "# The args fp32_* or fp16_* meant to be active when the\n",
    "# args fp16 is set. So the default behavior should all\n",
    "# be false.\n",
    "if not args.fp16:\n",
    "    args.fp32_embedding = False\n",
    "    args.fp32_tokentypes = False\n",
    "    args.fp32_layernorm = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HPARAMS_SCHEMA = {\n",
    "    '117m': dict(\n",
    "        num_layers=12,\n",
    "        hidden_size=768,\n",
    "        num_attention_heads=12,\n",
    "        max_position_embeddings=1024,\n",
    "    ),\n",
    "    '345m': dict(\n",
    "        num_layers=24,\n",
    "        hidden_size=1024,\n",
    "        num_attention_heads=16,\n",
    "        max_position_embeddings=1024,\n",
    "    ),\n",
    "}\n",
    "\n",
    "# 设置 GPT-2 模型的超参数\n",
    "for k, v in HPARAMS_SCHEMA[HPARAMS_NAME].items():\n",
    "    setattr(args, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(DDP_impl='local', attention_dropout=0.1, cache_dir=None, checkpoint_activations=None, checkpoint_num_layers=1, cuda=True, distributed_backend='nccl', dynamic_loss_scale=True, eod_mask_loss=None, finetune=None, fp16=True, greedy=False, hidden_dropout=0.1, hidden_size=768, hysteresis=2, load='./checkpoints/117m-hmwebmix_191128-bpe_v2', local_rank=None, loss_scale=None, loss_scale_window=1000, make_vocab_size_divisible_by=128, max_position_embeddings=1024, min_scale=1, model_parallel_size=1, no_load_optim=None, no_load_rng=None, num_attention_heads=12, num_layers=12, out_seq_length=256, rank=0, recompute=None, reset_attention_mask=None, reset_position_ids=None, resume_dataloader=None, seed=1234, seq_length=1024, temperature=1.0, tokenizer_model_type='bert-large-uncased', tokenizer_path='./data/spm/gpt2_huamei_corpus_bpe_32k_v2.model', tokenizer_type='GPT2BPETokenizer_CN', top_k=0, top_p=0.0, vocab_size=None, world_size=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化函数/全局变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = None\n",
    "model = None\n",
    "\n",
    "def initialize():\n",
    "    global model, tokenizer\n",
    "\n",
    "    # Disable CuDNN.\n",
    "    torch.backends.cudnn.enabled = False\n",
    "\n",
    "    # Pytorch distributed.\n",
    "    initialize_distributed(args)\n",
    "\n",
    "    # Random seeds for reproducability.\n",
    "    set_random_seed(args.seed)\n",
    "\n",
    "    # get the tokenizer\n",
    "    tokenizer = prepare_tokenizer(args)\n",
    "\n",
    "    # Model, optimizer, and learning rate.\n",
    "    model = setup_model(args)\n",
    "\n",
    "    args.device = torch.cuda.current_device()\n",
    "\n",
    "    # setting default batch size to 1\n",
    "    args.batch_size = 1\n",
    "\n",
    "    assert mpu.get_model_parallel_rank() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 主进程初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> initializing model parallel with size 1\n",
      "> initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234\n",
      "prepare tokenizer done\n",
      "building GPT2 model ...\n",
      " > number of parameters on model parallel rank 0: 110418432\n",
      "global rank 0 is loading checkpoint ./checkpoints/117m-hmwebmix_191128-bpe_v2/iter_0015000/mp_rank_00/model_optim_rng.pt\n",
      "  successfully loaded ./checkpoints/117m-hmwebmix_191128-bpe_v2/iter_0015000/mp_rank_00/model_optim_rng.pt\n",
      "CPU times: user 5.76 s, sys: 2.32 s, total: 8.08 s\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore generating args\n",
    "def reset_generating_args(args):\n",
    "    args.recompute=False\n",
    "    args.top_p=0\n",
    "    args.top_k=0\n",
    "    args.temperature=1\n",
    "\n",
    "def infer_tokens_generative(context_tokens, model, tokenizer):\n",
    "    with torch.no_grad():\n",
    "        context_length = len(context_tokens)\n",
    "        token_stream = get_token_stream(model, [context_tokens], tokenizer, args)   \n",
    "        for i, (output_tokens, _) in enumerate(token_stream):\n",
    "            if context_length + i >= args.seq_length:\n",
    "                break\n",
    "            ids = output_tokens.cpu().numpy().tolist()[0]\n",
    "            yield ids[-1]\n",
    "\n",
    "\n",
    "def infer_text_generative(contex_text, model, tokenizer):\n",
    "    with torch.no_grad():\n",
    "        contex_text = contex_text.strip()\n",
    "        context_tokens = tokenizer.EncodeAsIds(contex_text).tokenization\n",
    "        context_length = len(context_tokens)\n",
    "\n",
    "        token_stream = get_token_stream(model, [context_tokens], tokenizer, args)\n",
    "\n",
    "        for i, (output_tokens, _) in enumerate(token_stream):\n",
    "            if context_length + i >= args.seq_length:\n",
    "                break\n",
    "            ids = output_tokens.cpu().numpy().tolist()[0]\n",
    "            s = tokenizer.DecodeIds([ids[-1]])\n",
    "            yield s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测试试看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = [\n",
    "    # 这几个是 train 数据\n",
    "#     (\n",
    "#         '老公说和女老师是闺蜜?觉得老公精神出轨该怎么办?',\n",
    "#         '与老公关系越来越冷漠。离婚是想过，但离婚结果是伤害三个人，最重的是孩子。我比较敏感，觉得老公精神出轨，或亦是十多年磨合也抹掉对我的在乎，我的一切理所当然归他，他没有危机感。就让为人在就好，其他交流没有都可以。他可以同学，同事（尤其是女同事）一呼百应，对我的情绪和需求却时而不见。我也不知道该不该离?离伤己，伤孩，更伤父母，我不想做做样子的罪人。但我与老公的交流无效，我活在一口枯井里，抑郁得不行，加上单位效益差，想过重读书或考技能证专业，短期又不现实，再八年就退休了。真心累，找不到出口。嫉妒心又强，就连儿子亲近爸爸，我都会嫉恨孩子的做法，（我从不查丈夫，孩子的手机，结果个个都设密码，我有时候找不到手机，想借用都打不开。）压抑这样子愤怒的情绪的非常累。怎么办?',\n",
    "#     ),\n",
    "#     (\n",
    "#         '前任和现在的纠结',\n",
    "#         '是这样的，我和前任分手了 原因是他真的太好了 我觉得我会耽搁了他 最后逼走了前任 现在我和现任在一起了 可是每隔一段时间我就在痛心和前任的事情 总是忍不住想找前任 有一次忍不住发了个信息给前任 结果间接导致了前任和他的女友分手了（当时我不知道他在拍拖） 现任对我很好 可是老是吵嘴 可是我老是在比较 觉得现任和前任的差别 就不自主的挂念着前任 后悔当初怎么选择逼走他 觉得对不住前任 可是我的第一次阴差阳错的给了现任了 触碰了这个底线 可是我又想和前任一起 现在好纠结 您觉得我是应该好好珍惜现任呢 还是重新争取前任 我知道我现在就是等于三心两意 好贱 可是自己又由不得自己似得 好讨厌这样的自己',\n",
    "#     ),\n",
    "\n",
    "    # 这几个是网上随便找的数据\n",
    "    (\n",
    "        '男人出轨',\n",
    "        '我的意思是，出轨者会问自己，我为什么要这么做，被背叛的伴侣会问，你为什么要这样对我?'\n",
    "    ),\n",
    "    (\n",
    "        '我的奇葩婚姻，老公说为了孩子好就是不离婚？',\n",
    "        '我的婚姻最近好像一塌糊涂，可是老公不离婚，我甚至有想过死？我是不是得了抑郁症？和老公从2017年开始就吵吵闹闹，一吵架就分居，分居一两个月老公可以对我和孩子不问不闻，到时间了他就自己又搬回来，但是回来也不和我沟通，就算是上次是他动手，他也不道歉，他特别喜欢冷战。现在和老公又发展到了无性，而且双方家庭也合不来，我和他家人不敢来往，他家人对我要求高，希望天天在家做饭带娃伺候老公，他现在和我父母也不来往，从来不回家吃饭，要等我父母走了他才回来，每天很晚回家，去哪从来不告诉我，我知道他有婚外性，但他從來不承認，还说我是神经病，我還被他傳播上了高危型的HPV，以后是死是活都不确定，我特别想要离婚，我感觉和他生活快要窒息了，他整天拉着个脸，要么对我不闻不问，要么一开口说话就是责怪的语气，但他就是不离婚，说是为了孩子好，还让我不要发神经，我真的不知道该怎么和他相处了。他性格很古怪'\n",
    "    ),\n",
    "    (\n",
    "        '妻子在钱的问题上不坦诚，如何处理好家庭经济问题？',\n",
    "        '和老婆因为意外怀孕结婚，两家谈婚论嫁时闹得不愉快，我家出了一套大户型的房子，一台豪华车（当然这些都是婚前财产），然后给了40万装修婚房，同时给女方10万彩礼。而女方一开始的态度是一分钱没有，后来迫于压力给了50万现金，我老婆名下既没有房也没有车。婚后的钱一直都是给我老婆管理，包括我的工资奖金还有结婚的份子钱等等。我老婆并没有把这些钱看做是家庭财产，就算其中已经掺入了很多我的钱，还是认为全部都是她自己的钱，我只是知道她的卡密码而已，但是卡在哪里，她花了多少钱，花在哪里了，有没有借钱给别人，我通通不知道，这让我很不安。况且她没有理财观念，我曾经三番五次跟她说了理财的重要性，她就只是沉默不语，也不知道是听不懂，还是装傻实际上自己去做了理财但是没把收入情况告诉我，我们多次吵架都是为了钱，我觉得夫妻两个在这个问题上不能坦诚是个大问题，我现在很想经济分开，但是不知道怎么做才比较妥当'\n",
    "    ),\n",
    "    (\n",
    "        '30岁男生，相亲屡次不顺，我该怎么办呢？',\n",
    "        '30岁男生还单身，相亲对象不少，可是次次都以失败收场，自己长相还行，就是不太会说话，和女生聊天刚开始聊的挺不错，没聊几天女的就不回复了，爱答不理，心里郁闷的晚上都想哭，我该怎么办'\n",
    "    ),\n",
    "    (\n",
    "        '30岁女生，离婚念头挥之不去，他为何计划婚内出轨？',\n",
    "        '此刻有点儿失眠心情烦躁，我想了很久没有想明白，为什么他会计划着婚内出轨，……心里，我基本上认定原因应该是我身材不怎么好，胸部不够吸引人，因为婚后发现了在婚前，他约P了一个又肥又长相不佳的女人。我以为就是因为对方胸部傲人。在壹心理一些文章的引导下，我突然明白，源头是性生活不和谐。婚前同居一年多，到婚后2年，性生活基本就是，直奔主题，他一手拿着手机欣赏着他的成人影片一边爱爱，很少会主动关心我的感受，也很少理会我让他收起手机的要求。而且另一方面，他基本每晚都会要求我用嘴亲亲，他自己则拿着手机看片或者无关紧要的东西，让我经常觉得自己就是一个娃娃一个工具。以前我主动跟他说起过几次，然而也只是不了了之。后来我基本对性生活没有兴趣，也很反感为他口J。而且，日常生活变得频繁小吵冷战，很少有之前无话不谈的亲密，我不知道我们还有没有重归于好的机会……'\n",
    "    ),\n",
    "    (\n",
    "        '29岁哺乳期，和公婆因带孩子问题每天崩溃，怎么办？',\n",
    "        '怀孕她就没怎么管，备产各种东西都是自己准备。产后直接是妈妈照顾的。产后半年回来要上班，我爸妈又没退休，无奈下还是他们来照顾。他们方法不对，连个衣服都洗不干净，更不用提孩子的饭了。每天我都自己趁下班时间给孩子准备饭和各种东西。最怕的是习惯，比如她喜欢喂孩子各种炒菜，我说好几次一岁之内吃盐不好就是不听，还故意喂。或者孩子的奶瓶，经常不盖盖子让他把玩，说不卫生，也不搭理。孩子吃饭的碗和勺子永远是扔在各种桌子椅子角落，用的时候直接拿起来用也不洗，洗脸洗脚水每次告诉温度差不多就好了，就是不听，偏要一会冷一会烫。来我家被子也不叠，锅永远是不会洗的，下一顿加水加米接着煮。我老公又每天忙的不在家，我已经要崩溃了'\n",
    "    ),\n",
    "    (\n",
    "        '婚后分居三四年，有过家庭矛盾，我的婚姻是否该继续？',\n",
    "        '婚后分居三四年，和老公之间发生过一些家庭矛盾，可以看我另外一篇疑问。我们上半年闹离婚，后来他又主动和好，但是我们之前除了新婚，几乎很少有夫妻生活，他说一靠近我就觉得心里像一堆蚂蚁抓挠，特别难受。他说这是他得心理问题，小时候受到唾骂和凌辱，造成了心理阴影。我们俩都觉得生活的很痛苦，但为了孩子没有离婚。我跟他在一起就觉得拘束，不自在。向往的温馨家庭生活也得不到，我很累，我应该坚持离婚吗？他这种心理疾病是真的还是借口呢？'\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "男人出轨\n",
      "\n",
      "我的意思是，出轨者会问自己，我为什么要这么做，被背叛的伴侣会问，你为什么要这样对我?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "1:\t<|endoftext|>初恋再轰轰烈烈,爱情的地步紧会越冲淡原有的激情,所以,当然还是熬睡了。要记得把样子丢进他的改变,也就是改变了自己,每种标准的失利性,同时常伴随着很大的时间。在自我洗礼的方面上,他喜欢金,而你只想要一件。你坚持让对方去改变,对方就会改变,因为你们之间的看法更加信切。如果是你该如何做,而不是说咱俩。你心里充满怨言,的情感勒索与依赖,很难再长久,建议做情感咨询,让自己学会如何在他眼里多些认清自己,再去做父母》,对婚恋情感问题有深入的研究。点击我头像可以看到我的资历。我会从心理层面帮你分析指导如何找到心仪的另一半,教给你如何处理婚恋中的小矛盾和大问题,指导你如何在婚恋中进行有效的沟通相处。其实,婚恋关系问题一个很好的契机,如果处理的好,可以修补我们童年爱的缺失,打开我们的心结,让我们得到足够的成长。\n",
      "\n",
      "2:\t<|endoftext|>背叛你老婆,年龄越大,越怕伤害越大,心里罪恶感,有担忧与愤怒的感觉,会有这样的想法,五个月六个月本身,是什么?让自己变得更优秀,让老婆越好越不自信,让老婆越发感觉到罪感,于是最后就是嫌她出轨了,觉悟了,要不就是回头了。而男人不断的伤害你,换句话说,你根本不爱她,\n",
      "\n",
      "3:\t<|endoftext|>是怀疑,还是真实想法,男的说话都不看女的反应么亲...其实你看她眼睛,就知道她是不是愿意和你在一起。看出来太容易了。话不是很重要,她可能是怄气呢。但是眼神和表情和说话的气质骗不了人。大笨蛋\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "我的奇葩婚姻，老公说为了孩子好就是不离婚？\n",
      "\n",
      "我的婚姻最近好像一塌糊涂，可是老公不离婚，我甚至有想过死？我是不是得了抑郁症？和老公从2017年开始就吵吵闹闹，一吵架就分居，分居一两个月老公可以对我和孩子不问不闻，到时间了他就自己又搬回来，但是回来也不和我沟通，就算是上次是他动手，他也不道歉，他特别喜欢冷战。现在和老公又发展到了无性，而且双方家庭也合不来，我和他家人不敢来往，他家人对我要求高，希望天天在家做饭带娃伺候老公，他现在和我父母也不来往，从来不回家吃饭，要等我父母走了他才回来，每天很晚回家，去哪从来不告诉我，我知道他有婚外性，但他從來不承認，还说我是神经病，我還被他傳播上了高危型的HPV，以后是死是活都不确定，我特别想要离婚，我感觉和他生活快要窒息了，他整天拉着个脸，要么对我不闻不问，要么一开口说话就是责怪的语气，但他就是不离婚，说是为了孩子好，还让我不要发神经，我真的不知道该怎么和他相处了。他性格很古怪\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "1:\t<|endoftext|>你好,看来你很喜欢他,但是你却不知道怎么和他交流,感觉你们之间缺乏一点默契,这让我们不知道现在对方是否知道你的感受?此外需要你好好的互动和沟通,可以通过咨询来调整一下你们的沟通模式,从你也可以通过咨询的方式来寻找到你的幸福,希望能够帮助到你,\n",
      "\n",
      "2:\t<|endoftext|>你好,看来你很喜欢他,但是你却不知道怎么和他交流,感觉你们之间缺乏一点默契,所以你会觉得他不想和你说话,而他比较希望你不真诚。好像你在埋怨他,想让他能体会到你的感受以及需求,那么你们关系相处中,或许确实存在问题了,而已经到了无法进行沟通,因为不了解更多实际情况所以会这样,我们可以探讨更多,寻找解决问题的办法,如果有必要可以去看一下。\n",
      "\n",
      "3:\t<|endoftext|>你好,看来你对自己是有觉察的。不知道老公这样的行为带给你的感受是什么?有没有把你的想法和感受与他沟通?让他明白你的想法而不是生气不尊重你的做法?\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "妻子在钱的问题上不坦诚，如何处理好家庭经济问题？\n",
      "\n",
      "和老婆因为意外怀孕结婚，两家谈婚论嫁时闹得不愉快，我家出了一套大户型的房子，一台豪华车（当然这些都是婚前财产），然后给了40万装修婚房，同时给女方10万彩礼。而女方一开始的态度是一分钱没有，后来迫于压力给了50万现金，我老婆名下既没有房也没有车。婚后的钱一直都是给我老婆管理，包括我的工资奖金还有结婚的份子钱等等。我老婆并没有把这些钱看做是家庭财产，就算其中已经掺入了很多我的钱，还是认为全部都是她自己的钱，我只是知道她的卡密码而已，但是卡在哪里，她花了多少钱，花在哪里了，有没有借钱给别人，我通通不知道，这让我很不安。况且她没有理财观念，我曾经三番五次跟她说了理财的重要性，她就只是沉默不语，也不知道是听不懂，还是装傻实际上自己去做了理财但是没把收入情况告诉我，我们多次吵架都是为了钱，我觉得夫妻两个在这个问题上不能坦诚是个大问题，我现在很想经济分开，但是不知道怎么做才比较妥当\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "1:\t<|endoftext|>我感觉您希望经济分开的背后是委屈和恐惧。从叙述来看结婚最大的花销房子和车都是您这边出的,女方出的50万是“迫于压力”再加上婚后对这些财产没什么话语权,难免有种被剥削的感觉。婚后您愿意把钱给老婆管从某种程度说明了您对她的爱和信任,况且大头依然属于您的婚前财产。所以,也许您更需要她态度上的反馈,这种反馈应该和您的爱与信任相匹配。看一看有没有哪一次妻子愿意跟您讨论家里钱的问题,当时双方是如何沟通的,再把您可以接受的经济管理方式提出来,比如怎么做可以让您有安全感。当然最后实在想拿在自己手里,我相信您自己肯定有办法。\n",
      "\n",
      "2:\t<|endoftext|>我感觉您希望经济分开的背后是委屈和恐惧。从叙述来看结婚最大的花销房子和车都是您这边出的,女方出的50万是“迫于压力”再加上婚后对这些财产没什么话语权,难免有种被剥削的感觉。婚后您愿意把钱给老婆管从某种程度说明了您对她的爱和信任,况且大头依然属于您的婚前财产。所以,也许您更需要她态度上的反馈,这种反馈应该和您的爱与信任相匹配。看一看有没有哪一次妻子愿意跟您讨论家里钱的问题,当时双方是如何沟通的,再把您可以接受的经济管理方式提出来,比如怎么做可以让您有安全感。当然最后实在想拿在自己手里,我相信您自己肯定有办法。\n",
      "\n",
      "3:\t<|endoftext|>钱只是一面镜子,折射出来的却是两个人之间的矛盾问题,就像楼主所说的在婚前就已经闹的很不愉快,这就已经为婚后的夫妻生活埋下了隐患的基础,或许是楼主没有意识到问题的所在,亦或是不想去面对这些问题,任由问题存在而没有去解决。妻子婚后在钱的问题上不坦诚,让楼主的内心非常的不安,做为丈夫不了解妻子把共同财产用在哪里,换成是谁都会心里不安,这不仅仅是家庭经济问题,更是夫妻之间的相处交流存在的问题。因此,楼主想要解决家庭经济问题,可以先从解决夫妻之间的问题入手,和她好好谈谈,听听她的想法和感受,9再把自己的想法和感受表达给她,促进夫妻之间的情感交流,夫妻之间需要的是相互之间的尊重真诚信任理解,并不只是哪一方单纯这样就可以,是相互之间的关系影响。从楼主提供的信息来看,两个人之间缺乏合理有效的交流沟通,彼此之间缺乏了解理解和信任,解决了这些问题,那么剩下的家庭经济问题,也就不是问题了。\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "30岁男生，相亲屡次不顺，我该怎么办呢？\n",
      "\n",
      "30岁男生还单身，相亲对象不少，可是次次都以失败收场，自己长相还行，就是不太会说话，和女生聊天刚开始聊的挺不错，没聊几天女的就不回复了，爱答不理，心里郁闷的晚上都想哭，我该怎么办\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "1:\t<|endoftext|>感到楼主形成了一种模式,并不是敌意,而是有这样的意识,令楼主送过常规反馈,确实,至于是否还持续了一段时间啊?,感觉两个人姿态消气,划线,还是衡量清楚。婚姻是用来满足的,双人舞,也是互相帮助的。不过,之前,可以明白,两个人的结合也是一种保障,所以,建议你可以把内心的感受跟你老公沟通下,心平气和的告诉他,让他知道,你很需要他的空间。当你也需要感到被尊重和理解时,你就能更好的照顾好自己的情绪。\n",
      "\n",
      "2:\t<|endoftext|>我以前也喜欢过好几个女人,其实从心理学角度来说同性之间比异性之间更容易产生感情。喜欢同性太正常了啊,你再纠结什么?你想跟她发生关系么?\n",
      "\n",
      "3:\t<|endoftext|>放低姿态的人,对他一般动作的敏感或者因为对她占有欲极强,内心有一种比较自卑,总觉得有心魔气但是只是一种掩饰,比较酸刻薄的性格,容易与女生打交道。这并不是病,只是一种犯错的价值观,它或许是一个突出的心结。当你向女朋友发脾气的时候,你献出了拒绝,但在一起后发生不愉快,女孩让你感觉不舒服,对吗?\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "30岁女生，离婚念头挥之不去，他为何计划婚内出轨？\n",
      "\n",
      "此刻有点儿失眠心情烦躁，我想了很久没有想明白，为什么他会计划着婚内出轨，……心里，我基本上认定原因应该是我身材不怎么好，胸部不够吸引人，因为婚后发现了在婚前，他约P了一个又肥又长相不佳的女人。我以为就是因为对方胸部傲人。在壹心理一些文章的引导下，我突然明白，源头是性生活不和谐。婚前同居一年多，到婚后2年，性生活基本就是，直奔主题，他一手拿着手机欣赏着他的成人影片一边爱爱，很少会主动关心我的感受，也很少理会我让他收起手机的要求。而且另一方面，他基本每晚都会要求我用嘴亲亲，他自己则拿着手机看片或者无关紧要的东西，让我经常觉得自己就是一个娃娃一个工具。以前我主动跟他说起过几次，然而也只是不了了之。后来我基本对性生活没有兴趣，也很反感为他口J。而且，日常生活变得频繁小吵冷战，很少有之前无话不谈的亲密，我不知道我们还有没有重归于好的机会……\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "1:\t<|endoftext|>你好,你提到要“你内心接受”才可以进入你的世界,但你现在在结交异性方面,你有给他们机会了解你吗?如果他们对你都不了解,怎么让你接受他呢?\n",
      "\n",
      "2:\t<|endoftext|>你好,从你的描述来看,你老公并没有出轨这件事情,并且对于他有出格的过错,他虽然只是口头上说一下,如果他爱你,或者他依然爱着你,你也感觉不到!所以,如果你想和她结婚,就去和这个女孩在一起,却发现不可理喻,那就果断说清楚,然后不再藕断丝连。我从来没有考虑过她究竟是爱吗?还是只是单纯的性?不知道你的这个女孩已经知道自己的老公是否出轨了呢?如果爱,请慎重考虑。\n",
      "\n",
      "3:\t<|endoftext|>生活的着不是那么容易,也许跟某些曾经的经历有关,也许幼年的某些经历,造成了现在的某些单亲或缺。我不知道你描述的情况,对你的建议是直接拒绝,或者说是你很反感,以至于你都没有受伤。我不了解你和他的成长经历,所以会对能更深入的分析,也许上面的几段话,会让你更了解他某些方面,你的潜意识中,你要更深刻地了解你自己,也能更多的认识到你。\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "29岁哺乳期，和公婆因带孩子问题每天崩溃，怎么办？\n",
      "\n",
      "怀孕她就没怎么管，备产各种东西都是自己准备。产后直接是妈妈照顾的。产后半年回来要上班，我爸妈又没退休，无奈下还是他们来照顾。他们方法不对，连个衣服都洗不干净，更不用提孩子的饭了。每天我都自己趁下班时间给孩子准备饭和各种东西。最怕的是习惯，比如她喜欢喂孩子各种炒菜，我说好几次一岁之内吃盐不好就是不听，还故意喂。或者孩子的奶瓶，经常不盖盖子让他把玩，说不卫生，也不搭理。孩子吃饭的碗和勺子永远是扔在各种桌子椅子角落，用的时候直接拿起来用也不洗，洗脸洗脚水每次告诉温度差不多就好了，就是不听，偏要一会冷一会烫。来我家被子也不叠，锅永远是不会洗的，下一顿加水加米接着煮。我老公又每天忙的不在家，我已经要崩溃了\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "1:\t<|endoftext|>楼主你好,我是小媒。一般来说,怀孕的人是最需要丈夫的关心和体贴的。最需要的是夫妻之间的沟通。楼主可以尝试跟亲人朋友倾诉一下,让大家帮你出谋划策,呼气,说不定你会更加快乐～\n",
      "\n",
      "2:\t<|endoftext|>楼主你好,我是五花肉~有意见当然是需要说出来,如果实在不需要,很多家务不做,没有家的矛盾,也会导致与家人的关系恶化。楼主的这种状态实际上有可能是反映出楼主对待自己的婚姻,把老公的这种应对方式显得理所应当,偏向于婆婆。楼主提到【\n",
      "\n",
      "3:\t<|endoftext|>楼主你好,我是小媒。很心疼楼主。听楼主说话的口气,好像对方反抗了你很生气。应该是老公的身份,让你感觉委屈,无助成了愤怒的武器,而他恰好是一个“反向”大吵不断。对于他你的情绪反应,似乎采用“你”、“高压政策”的姿态,对吗?这些情绪是需要系统排解的部分,会让你的情绪更加激烈,所以建议你尝试咨询,挖掘下正规的思维模式,对大家一生都是不一样的。\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "婚后分居三四年，有过家庭矛盾，我的婚姻是否该继续？\n",
      "\n",
      "婚后分居三四年，和老公之间发生过一些家庭矛盾，可以看我另外一篇疑问。我们上半年闹离婚，后来他又主动和好，但是我们之前除了新婚，几乎很少有夫妻生活，他说一靠近我就觉得心里像一堆蚂蚁抓挠，特别难受。他说这是他得心理问题，小时候受到唾骂和凌辱，造成了心理阴影。我们俩都觉得生活的很痛苦，但为了孩子没有离婚。我跟他在一起就觉得拘束，不自在。向往的温馨家庭生活也得不到，我很累，我应该坚持离婚吗？他这种心理疾病是真的还是借口呢？\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "1:\t<|endoftext|>你好,能够理解你的心情。你老公已经习惯性出轨,可想而知,你欣赏他的哪些方面?现在还想要挽回他吗?先好好过日子,很美好,很明显就是在暂时的呈现他的态度,没有引起重视,这让你有些厌恶,是这样吗?你能选择来这里求助,就非常的不简单。咨询是一个过程,我需要了解更多的情况,才能帮你分析解决问题。我帮助过很多和你一样困扰的人,相信也可以帮到你。可以多说一些你的情况吗?\n",
      "\n",
      "2:\t<|endoftext|>你好,能够理解你的心情。可以感受到你的不容易。从结婚前就不断的遭遇家暴,只因为不想让孩子没有出生的机会,你能选择来这里求助,就非常的不简单。咨询是一个过程,我需要了解更多的情况,才能帮你分析解决问题。我帮助过很多和你一样困扰的人,相信也可以帮到你。可以多说一些你的情况吗?\n",
      "\n",
      "3:\t<|endoftext|>你好,能够理解你的心情。你老公的所做所为,让我们每个人都有自己的价值观和生活习惯。你要求他每天出去吃饭,可以主动和他说话,而不是他一个人,这样他的观念就是和孩子教育孩子的观念,你的妈妈并没有记住你们什么而是和别的孩子一样,你们的成长经历和养育环境应该是你们两人共同参与,他养你的不是,他的成长是你依赖他的理由,你需要尊重他。\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_gen = 3\n",
    "\n",
    "reset_generating_args(args)\n",
    "try:\n",
    "#     args.recompute = True\n",
    "    for title, text in input_texts:\n",
    "        context_string = f'{title}<sep>{text}<sep><sep>'\n",
    "#         context_string += '<|endoftext|>'\n",
    "        print(title)\n",
    "        print()\n",
    "        print(text)\n",
    "        print('-' * 100)\n",
    "        print()\n",
    "        for i in range(n_gen):\n",
    "            args.top_p=random.gauss(0.5, 0.5)\n",
    "            args.temperature=random.gauss(1, 0.05)\n",
    "            print(f'{i+1}:\\t', end='')\n",
    "            context_tokens = tokenizer.EncodeAsIds(context_string).tokenization\n",
    "            for id_ in infer_tokens_generative(context_tokens, model, tokenizer):\n",
    "                s = tokenizer.DecodeIds([id_])\n",
    "                print(s, end='')\n",
    "            print(os.linesep)\n",
    "        print()\n",
    "        print('=' * 100)\n",
    "        print()\n",
    "finally:\n",
    "    reset_generating_args(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 test 语料，从中随机打断，并预测下文，比较原文与预测结果！\n",
    "\n",
    "随机选 N 个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_file=./data/xinliqa-hunyin/test.infer-345m.iter_0050000-200x256x5-shuffle_False-191125120008.tsv\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "ts = datetime.now().strftime('%y%m%d%H%M%S')\n",
    "\n",
    "\n",
    "N = 200\n",
    "SHUFFLING = False\n",
    "INFER_COUNT = 5\n",
    "\n",
    "input_file = './data/xinliqa-hunyin/test.json'\n",
    "output_file = f'./data/xinliqa-hunyin/test.infer-{HPARAMS_NAME}.{iteration_dir}-{N}x{args.out_seq_length}x{INFER_COUNT}-shuffle_{SHUFFLING}-{ts}.tsv'\n",
    "\n",
    "print(f'output_file={output_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c10fdf19924ecbac78cf2cde3311e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test 数据总数: 1,885\n",
      "Test 采样数: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0381dfc8cbae433096b4e14cfddf01c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='sample', max=200, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5859d72354d4f4c971b7254ef73cd32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='generate', max=200, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total = sum(1 for _ in tqdm(open(input_file)))\n",
    "print(f'Test 数据总数: {total:,d}')\n",
    "\n",
    "assert total >= N\n",
    "\n",
    "print(f'Test 采样数: {N:,d}')\n",
    "\n",
    "mask = np.zeros(total, dtype=int)\n",
    "mask[:N] = 1\n",
    "if SHUFFLING:\n",
    "    np.random.shuffle(mask)\n",
    "\n",
    "samples = []\n",
    "with open(input_file) as fp:\n",
    "    reader = compress(fp, mask)\n",
    "    for line in tqdm(reader, 'sample', total=N):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        text = json.loads(line)['text']\n",
    "        question, answer = text.strip().split('<|endoftext|>')\n",
    "        question_title, question_text = question.split('<sep>')[:2]\n",
    "        samples.append([question_title, question_text, answer])\n",
    "if SHUFFLING:\n",
    "    random.shuffle(samples)\n",
    "\n",
    "with open(output_file, 'w') as fp:\n",
    "    writer = csv.writer(fp, delimiter='\\t')\n",
    "    for question_title, question_text, answer in tqdm(samples, 'generate'):\n",
    "        row = [question_title, question_text, answer]\n",
    "        txt = f'{question_title}<sep>{question_text}<sep><sep><|endoftext|>'\n",
    "        for _ in range(INFER_COUNT):\n",
    "            reset_generating_args(args)\n",
    "            try:\n",
    "                args.recompute=True\n",
    "                args.top_p=random.gauss(0.5, 0.5)\n",
    "                args.temperature=random.gauss(1, 0.05)\n",
    "                infer_txt = ''.join(infer_text_generative(txt, model, tokenizer))\n",
    "                row.append(infer_txt)                \n",
    "            finally:\n",
    "                reset_generating_args(args)\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Megatron_LM-ipy]",
   "language": "python",
   "name": "conda-env-Megatron_LM-ipy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
